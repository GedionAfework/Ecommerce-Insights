{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook performs comprehensive exploratory analysis of the fused e-commerce dataset.\n",
        "\n",
        "## Objectives\n",
        "1. Understand dataset structure and quality\n",
        "2. Analyze distributions of key variables\n",
        "3. Explore relationships between features\n",
        "4. Perform statistical tests\n",
        "5. Generate visualizations\n",
        "6. Document insights and findings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'ecom (Python 3.13.5)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Project paths\n",
        "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "PROCESSED_DIR = DATA_DIR / \"processed\" / \"fused\"\n",
        "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
        "FIGURES_DIR = REPORTS_DIR / \"figures\"\n",
        "\n",
        "# Create figures directory if it doesn't exist\n",
        "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Processed data: {PROCESSED_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Fused Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load fused dataset with ULTRA memory-efficient approach to prevent IDE crashes\n",
        "import pyarrow.parquet as pq\n",
        "import gc\n",
        "\n",
        "fused_file = PROCESSED_DIR / \"books_books_fused.parquet\"\n",
        "\n",
        "print(f\"Loading fused dataset from: {fused_file}\")\n",
        "print(f\"File exists: {fused_file.exists()}\")\n",
        "\n",
        "# ULTRA conservative loading: Maximum 50,000 rows to prevent IDE crashes\n",
        "if fused_file.exists():\n",
        "    # Read metadata without loading full dataset\n",
        "    parquet_file = pq.ParquetFile(fused_file)\n",
        "    num_rows = parquet_file.metadata.num_rows\n",
        "    file_size_mb = fused_file.stat().st_size / (1024**2)\n",
        "    num_row_groups = parquet_file.num_row_groups\n",
        "    \n",
        "    print(f\"File size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"Total rows in file: {num_rows:,}\")\n",
        "    print(f\"Number of row groups: {num_row_groups}\")\n",
        "    \n",
        "    # VERY conservative sample size - max 50k rows to prevent IDE crashes\n",
        "    MAX_SAMPLE_SIZE = 50_000  # Hard limit to prevent crashes\n",
        "    \n",
        "    if num_rows > MAX_SAMPLE_SIZE:\n",
        "        sample_size = MAX_SAMPLE_SIZE\n",
        "        print(f\"\\n⚠️  Dataset is VERY large ({num_rows:,} rows).\")\n",
        "        print(f\"   Sampling {sample_size:,} rows for EDA to prevent IDE crashes...\")\n",
        "        print(f\"   This represents {sample_size/num_rows*100:.2f}% of the full dataset.\")\n",
        "        \n",
        "        # Read only 1-2 row groups at a time to minimize memory usage\n",
        "        max_row_groups_to_read = min(2, num_row_groups)  # Read max 2 row groups\n",
        "        row_groups_to_read = sorted(np.random.choice(num_row_groups, \n",
        "                                                      size=max_row_groups_to_read, \n",
        "                                                      replace=False,\n",
        "                                                      random_state=42))\n",
        "        \n",
        "        print(f\"Reading {len(row_groups_to_read)} row groups...\")\n",
        "        batches = []\n",
        "        \n",
        "        for rg_idx in row_groups_to_read:\n",
        "            try:\n",
        "                # Read row group\n",
        "                batch = parquet_file.read_row_groups([rg_idx]).to_pandas()\n",
        "                \n",
        "                # Immediately optimize data types to save memory\n",
        "                for col in batch.columns:\n",
        "                    if batch[col].dtype == 'object':\n",
        "                        # Convert to category if low cardinality\n",
        "                        if batch[col].nunique() / len(batch) < 0.5:\n",
        "                            batch[col] = batch[col].astype('category')\n",
        "                    elif batch[col].dtype == 'int64':\n",
        "                        batch[col] = pd.to_numeric(batch[col], downcast='integer')\n",
        "                    elif batch[col].dtype == 'float64':\n",
        "                        batch[col] = pd.to_numeric(batch[col], downcast='float')\n",
        "                \n",
        "                batches.append(batch)\n",
        "                \n",
        "                # Early exit if we have enough data\n",
        "                total_rows_so_far = sum(len(b) for b in batches)\n",
        "                if total_rows_so_far >= sample_size * 1.5:  # Get 1.5x for better sampling\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not read row group {rg_idx}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if batches:\n",
        "            # Combine batches and sample\n",
        "            print(\"Combining batches...\")\n",
        "            df_temp = pd.concat(batches, ignore_index=True)\n",
        "            print(f\"Combined batches: {len(df_temp):,} rows\")\n",
        "            \n",
        "            # Free memory immediately\n",
        "            del batches\n",
        "            gc.collect()\n",
        "            \n",
        "            # Sample to exact size\n",
        "            if len(df_temp) > sample_size:\n",
        "                df_sample = df_temp.sample(n=sample_size, random_state=42)\n",
        "            else:\n",
        "                df_sample = df_temp.copy()\n",
        "            \n",
        "            # Free memory\n",
        "            del df_temp\n",
        "            gc.collect()\n",
        "            \n",
        "            # Final optimization\n",
        "            print(\"Final data type optimization...\")\n",
        "            for col in df_sample.columns:\n",
        "                if df_sample[col].dtype == 'object':\n",
        "                    if df_sample[col].nunique() / len(df_sample) < 0.5:\n",
        "                        df_sample[col] = df_sample[col].astype('category')\n",
        "                elif df_sample[col].dtype == 'int64':\n",
        "                    df_sample[col] = pd.to_numeric(df_sample[col], downcast='integer')\n",
        "                elif df_sample[col].dtype == 'float64':\n",
        "                    df_sample[col] = pd.to_numeric(df_sample[col], downcast='float')\n",
        "        else:\n",
        "            raise ValueError(\"Could not read any data from parquet file\")\n",
        "    else:\n",
        "        # Small dataset - load directly\n",
        "        print(\"Loading full dataset (small enough to load directly)...\")\n",
        "        df_sample = pd.read_parquet(fused_file)\n",
        "        \n",
        "        # Optimize data types\n",
        "        for col in df_sample.columns:\n",
        "            if df_sample[col].dtype == 'object':\n",
        "                if df_sample[col].nunique() / len(df_sample) < 0.5:\n",
        "                    df_sample[col] = df_sample[col].astype('category')\n",
        "            elif df_sample[col].dtype == 'int64':\n",
        "                df_sample[col] = pd.to_numeric(df_sample[col], downcast='integer')\n",
        "            elif df_sample[col].dtype == 'float64':\n",
        "                df_sample[col] = pd.to_numeric(df_sample[col], downcast='float')\n",
        "    \n",
        "    # Final garbage collection\n",
        "    gc.collect()\n",
        "    \n",
        "    print(f\"\\n✅ Dataset loaded successfully!\")\n",
        "    print(f\"   Shape: {df_sample.shape}\")\n",
        "    print(f\"   Memory usage: {df_sample.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    if num_rows > MAX_SAMPLE_SIZE:\n",
        "        print(f\"   Sample represents: {len(df_sample)/num_rows*100:.2f}% of full dataset\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"File not found: {fused_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic info\n",
        "print(\"=== DATASET OVERVIEW ===\")\n",
        "print(f\"Rows: {len(df_sample):,}\")\n",
        "print(f\"Columns: {len(df_sample.columns)}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "for i, col in enumerate(df_sample.columns, 1):\n",
        "    print(f\"  {i:2d}. {col}\")\n",
        "\n",
        "print(\"\\n=== DATA TYPES ===\")\n",
        "print(df_sample.dtypes)\n",
        "\n",
        "print(\"\\n=== MISSING VALUES ===\")\n",
        "missing = df_sample.isnull().sum()\n",
        "missing_pct = (missing / len(df_sample)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing.index,\n",
        "    'Missing Count': missing.values,\n",
        "    'Missing %': missing_pct.values\n",
        "})\n",
        "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "print(missing_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Review Features Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rating distribution\n",
        "print(\"=== RATING DISTRIBUTION ===\")\n",
        "if 'overall' in df_sample.columns:\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    print(rating_counts)\n",
        "    print(f\"\\nMean rating: {df_sample['overall'].mean():.2f}\")\n",
        "    print(f\"Median rating: {df_sample['overall'].median():.2f}\")\n",
        "    print(f\"Std deviation: {df_sample['overall'].std():.2f}\")\n",
        "\n",
        "# Review text length\n",
        "print(\"\\n=== REVIEW TEXT LENGTH ===\")\n",
        "if 'review_length_chars' in df_sample.columns:\n",
        "    print(f\"Mean characters: {df_sample['review_length_chars'].mean():.0f}\")\n",
        "    print(f\"Median characters: {df_sample['review_length_chars'].median():.0f}\")\n",
        "    print(f\"Mean words: {df_sample['review_length_words'].mean():.0f}\")\n",
        "    print(f\"Median words: {df_sample['review_length_words'].median():.0f}\")\n",
        "\n",
        "# Helpfulness\n",
        "print(\"\\n=== HELPFULNESS METRICS ===\")\n",
        "if 'helpfulness_ratio' in df_sample.columns:\n",
        "    helpful = df_sample['helpfulness_ratio'].dropna()\n",
        "    if len(helpful) > 0:\n",
        "        print(f\"Mean helpfulness ratio: {helpful.mean():.3f}\")\n",
        "        print(f\"Median helpfulness ratio: {helpful.median():.3f}\")\n",
        "\n",
        "# Verification\n",
        "print(\"\\n=== VERIFICATION STATUS ===\")\n",
        "if 'is_verified' in df_sample.columns:\n",
        "    verified_counts = df_sample['is_verified'].value_counts()\n",
        "    print(verified_counts)\n",
        "    print(f\"Verified %: {verified_counts.get(True, 0) / len(df_sample) * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rating distribution - Multiple visualizations\n",
        "if 'overall' in df_sample.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Bar chart\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    axes[0].bar(rating_counts.index, rating_counts.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[0].set_title('Rating Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Rating', fontsize=12)\n",
        "    axes[0].set_ylabel('Count', fontsize=12)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    axes[0].set_xticks(rating_counts.index)\n",
        "    \n",
        "    # Pie chart\n",
        "    colors = ['#ff4444', '#ff8800', '#ffbb00', '#88cc00', '#00aa00']\n",
        "    axes[1].pie(rating_counts.values, labels=rating_counts.index, autopct='%1.1f%%', \n",
        "                colors=colors[:len(rating_counts)], startangle=90)\n",
        "    axes[1].set_title('Rating Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'rating_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Rating distribution statistics\n",
        "    print(f\"\\nRating Statistics:\")\n",
        "    print(f\"Mean: {df_sample['overall'].mean():.2f}\")\n",
        "    print(f\"Median: {df_sample['overall'].median():.2f}\")\n",
        "    print(f\"Mode: {df_sample['overall'].mode()[0]}\")\n",
        "    print(f\"Std Dev: {df_sample['overall'].std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review length distribution - Enhanced visualization\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Histogram\n",
        "    review_lengths = df_sample['review_length_words'].clip(upper=500)\n",
        "    axes[0].hist(review_lengths, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0].axvline(review_lengths.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {review_lengths.mean():.0f}')\n",
        "    axes[0].axvline(review_lengths.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {review_lengths.median():.0f}')\n",
        "    axes[0].set_title('Review Length Distribution (Words)', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Number of Words', fontsize=12)\n",
        "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Box plot\n",
        "    axes[1].boxplot(review_lengths, vert=True, patch_artist=True,\n",
        "                    boxprops=dict(facecolor='steelblue', alpha=0.7))\n",
        "    axes[1].set_title('Review Length Box Plot', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_ylabel('Number of Words', fontsize=12)\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'review_length_distribution.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Statistics\n",
        "    print(f\"\\nReview Length Statistics:\")\n",
        "    print(f\"Mean: {df_sample['review_length_words'].mean():.1f} words\")\n",
        "    print(f\"Median: {df_sample['review_length_words'].median():.1f} words\")\n",
        "    print(f\"Min: {df_sample['review_length_words'].min():.0f} words\")\n",
        "    print(f\"Max: {df_sample['review_length_words'].max():.0f} words\")\n",
        "    print(f\"Q1: {df_sample['review_length_words'].quantile(0.25):.1f} words\")\n",
        "    print(f\"Q3: {df_sample['review_length_words'].quantile(0.75):.1f} words\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rating vs Review Length - Enhanced analysis\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Scatter plot with density\n",
        "    plot_sample = df_sample.sample(n=min(10000, len(df_sample)), random_state=42)\n",
        "    scatter = axes[0].scatter(plot_sample['review_length_words'], plot_sample['overall'], \n",
        "                              alpha=0.4, s=15, c=plot_sample['overall'], \n",
        "                              cmap='viridis', edgecolors='none')\n",
        "    axes[0].set_title('Rating vs Review Length (Scatter)', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Review Length (Words)', fontsize=12)\n",
        "    axes[0].set_ylabel('Rating', fontsize=12)\n",
        "    axes[0].grid(alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=axes[0], label='Rating')\n",
        "    \n",
        "    # Box plot by rating\n",
        "    rating_groups = [df_sample[df_sample['overall'] == rating]['review_length_words'].values \n",
        "                     for rating in sorted(df_sample['overall'].unique())]\n",
        "    bp = axes[1].boxplot(rating_groups, labels=sorted(df_sample['overall'].unique()),\n",
        "                         patch_artist=True, vert=True)\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('steelblue')\n",
        "        patch.set_alpha(0.7)\n",
        "    axes[1].set_title('Review Length by Rating', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Rating', fontsize=12)\n",
        "    axes[1].set_ylabel('Review Length (Words)', fontsize=12)\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'rating_vs_length.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Correlation\n",
        "    corr = df_sample[['overall', 'review_length_words']].corr().iloc[0, 1]\n",
        "    print(f\"\\nCorrelation between Rating and Review Length: {corr:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1 Additional Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verified vs Non-Verified Purchase Comparison\n",
        "if 'is_verified' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # Rating distribution comparison\n",
        "    verified_ratings = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "    non_verified_ratings = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "    \n",
        "    # Violin plot\n",
        "    data_to_plot = [verified_ratings.values, non_verified_ratings.values]\n",
        "    parts = axes[0].violinplot(data_to_plot, positions=[1, 2], showmeans=True, showmedians=True)\n",
        "    for pc in parts['bodies']:\n",
        "        pc.set_facecolor('steelblue')\n",
        "        pc.set_alpha(0.7)\n",
        "    axes[0].set_xticks([1, 2])\n",
        "    axes[0].set_xticklabels(['Verified', 'Non-Verified'])\n",
        "    axes[0].set_ylabel('Rating', fontsize=12)\n",
        "    axes[0].set_title('Rating Distribution: Verified vs Non-Verified', fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Side-by-side bar chart\n",
        "    verified_counts = verified_ratings.value_counts().sort_index()\n",
        "    non_verified_counts = non_verified_ratings.value_counts().sort_index()\n",
        "    x = np.arange(len(verified_counts))\n",
        "    width = 0.35\n",
        "    \n",
        "    axes[1].bar(x - width/2, verified_counts.values, width, label='Verified', alpha=0.8, color='green')\n",
        "    axes[1].bar(x + width/2, non_verified_counts.values, width, label='Non-Verified', alpha=0.8, color='orange')\n",
        "    axes[1].set_xlabel('Rating', fontsize=12)\n",
        "    axes[1].set_ylabel('Count', fontsize=12)\n",
        "    axes[1].set_title('Rating Counts: Verified vs Non-Verified', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xticks(x)\n",
        "    axes[1].set_xticklabels(verified_counts.index)\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'verified_vs_nonverified.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nVerified Purchase Statistics:\")\n",
        "    print(f\"  Mean Rating: {verified_ratings.mean():.2f}\")\n",
        "    print(f\"  Median Rating: {verified_ratings.median():.2f}\")\n",
        "    print(f\"  Count: {len(verified_ratings):,}\")\n",
        "    print(f\"\\nNon-Verified Purchase Statistics:\")\n",
        "    print(f\"  Mean Rating: {non_verified_ratings.mean():.2f}\")\n",
        "    print(f\"  Median Rating: {non_verified_ratings.median():.2f}\")\n",
        "    print(f\"  Count: {len(non_verified_ratings):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpfulness Analysis\n",
        "if 'helpfulness_ratio' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    helpful_data = df_sample['helpfulness_ratio'].dropna()\n",
        "    \n",
        "    # Helpfulness distribution\n",
        "    axes[0, 0].hist(helpful_data, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].axvline(helpful_data.mean(), color='red', linestyle='--', linewidth=2, \n",
        "                       label=f'Mean: {helpful_data.mean():.3f}')\n",
        "    axes[0, 0].set_title('Helpfulness Ratio Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Helpfulness Ratio', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Helpfulness vs Rating\n",
        "    plot_sample = df_sample.sample(n=min(10000, len(df_sample)), random_state=42)\n",
        "    helpful_sample = plot_sample[plot_sample['helpfulness_ratio'].notna()]\n",
        "    if len(helpful_sample) > 0:\n",
        "        scatter = axes[0, 1].scatter(helpful_sample['helpfulness_ratio'], \n",
        "                                     helpful_sample['overall'],\n",
        "                                     alpha=0.5, s=20, c=helpful_sample['overall'], \n",
        "                                     cmap='coolwarm', edgecolors='none')\n",
        "        axes[0, 1].set_title('Helpfulness vs Rating', fontsize=14, fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Helpfulness Ratio', fontsize=12)\n",
        "        axes[0, 1].set_ylabel('Rating', fontsize=12)\n",
        "        axes[0, 1].grid(alpha=0.3)\n",
        "        plt.colorbar(scatter, ax=axes[0, 1], label='Rating')\n",
        "    \n",
        "    # Average helpfulness by rating\n",
        "    if len(helpful_sample) > 0:\n",
        "        avg_helpful_by_rating = helpful_sample.groupby('overall')['helpfulness_ratio'].mean()\n",
        "        axes[1, 0].bar(avg_helpful_by_rating.index, avg_helpful_by_rating.values, \n",
        "                       color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        axes[1, 0].set_title('Average Helpfulness by Rating', fontsize=14, fontweight='bold')\n",
        "        axes[1, 0].set_xlabel('Rating', fontsize=12)\n",
        "        axes[1, 0].set_ylabel('Average Helpfulness Ratio', fontsize=12)\n",
        "        axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "        axes[1, 0].set_xticks(avg_helpful_by_rating.index)\n",
        "    \n",
        "    # Helpfulness box plot by rating\n",
        "    if len(helpful_sample) > 0:\n",
        "        helpful_groups = [helpful_sample[helpful_sample['overall'] == rating]['helpfulness_ratio'].values \n",
        "                          for rating in sorted(helpful_sample['overall'].unique())]\n",
        "        bp = axes[1, 1].boxplot(helpful_groups, labels=sorted(helpful_sample['overall'].unique()),\n",
        "                               patch_artist=True, vert=True)\n",
        "        for patch in bp['boxes']:\n",
        "            patch.set_facecolor('steelblue')\n",
        "            patch.set_alpha(0.7)\n",
        "        axes[1, 1].set_title('Helpfulness Distribution by Rating', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Rating', fontsize=12)\n",
        "        axes[1, 1].set_ylabel('Helpfulness Ratio', fontsize=12)\n",
        "        axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'helpfulness_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    if len(helpful_data) > 0:\n",
        "        print(f\"\\nHelpfulness Statistics:\")\n",
        "        print(f\"  Mean: {helpful_data.mean():.3f}\")\n",
        "        print(f\"  Median: {helpful_data.median():.3f}\")\n",
        "        print(f\"  Std Dev: {helpful_data.std():.3f}\")\n",
        "        print(f\"  Min: {helpful_data.min():.3f}\")\n",
        "        print(f\"  Max: {helpful_data.max():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Product-level Analysis (if product ID available)\n",
        "product_cols = [col for col in df_sample.columns if 'product' in col.lower() or 'asin' in col.lower()]\n",
        "\n",
        "if product_cols and 'overall' in df_sample.columns:\n",
        "    product_col = product_cols[0]\n",
        "    print(f\"Analyzing products using column: {product_col}\")\n",
        "    \n",
        "    # Top products by review count\n",
        "    top_products = df_sample[product_col].value_counts().head(10)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Top 10 products by review count\n",
        "    axes[0, 0].barh(range(len(top_products)), top_products.values, color='steelblue', alpha=0.7)\n",
        "    axes[0, 0].set_yticks(range(len(top_products)))\n",
        "    axes[0, 0].set_yticklabels([f\"Product {i+1}\" for i in range(len(top_products))])\n",
        "    axes[0, 0].set_xlabel('Number of Reviews', fontsize=12)\n",
        "    axes[0, 0].set_title('Top 10 Products by Review Count', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # Average rating by product (top 10)\n",
        "    top_product_ids = top_products.index[:10]\n",
        "    avg_ratings = df_sample[df_sample[product_col].isin(top_product_ids)].groupby(product_col)['overall'].mean().sort_values(ascending=False)\n",
        "    axes[0, 1].barh(range(len(avg_ratings)), avg_ratings.values, color='coral', alpha=0.7)\n",
        "    axes[0, 1].set_yticks(range(len(avg_ratings)))\n",
        "    axes[0, 1].set_yticklabels([f\"Product {i+1}\" for i in range(len(avg_ratings))])\n",
        "    axes[0, 1].set_xlabel('Average Rating', fontsize=12)\n",
        "    axes[0, 1].set_title('Average Rating for Top 10 Products', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlim([0, 5])\n",
        "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # Review count distribution\n",
        "    review_counts_per_product = df_sample[product_col].value_counts()\n",
        "    axes[1, 0].hist(review_counts_per_product.values, bins=50, color='steelblue', \n",
        "                    edgecolor='black', alpha=0.7)\n",
        "    axes[1, 0].set_title('Distribution of Reviews per Product', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Number of Reviews', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Number of Products', fontsize=12)\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Average rating distribution across products\n",
        "    avg_ratings_all = df_sample.groupby(product_col)['overall'].mean()\n",
        "    axes[1, 1].hist(avg_ratings_all.values, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "    axes[1, 1].axvline(avg_ratings_all.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                       label=f'Mean: {avg_ratings_all.mean():.2f}')\n",
        "    axes[1, 1].set_title('Distribution of Average Ratings per Product', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Average Rating', fontsize=12)\n",
        "    axes[1, 1].set_ylabel('Number of Products', fontsize=12)\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'product_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nProduct Statistics:\")\n",
        "    print(f\"  Total unique products: {df_sample[product_col].nunique():,}\")\n",
        "    print(f\"  Average reviews per product: {review_counts_per_product.mean():.1f}\")\n",
        "    print(f\"  Median reviews per product: {review_counts_per_product.median():.1f}\")\n",
        "    print(f\"  Average rating across all products: {avg_ratings_all.mean():.2f}\")\n",
        "else:\n",
        "    print(\"Product ID column not found. Skipping product-level analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 Advanced Statistical Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution comparison plots\n",
        "if 'overall' in df_sample.columns:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Q-Q plot for rating distribution (checking normality)\n",
        "    from scipy import stats\n",
        "    stats.probplot(df_sample['overall'], dist=\"norm\", plot=axes[0, 0])\n",
        "    axes[0, 0].set_title('Q-Q Plot: Rating Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Cumulative distribution\n",
        "    sorted_ratings = np.sort(df_sample['overall'])\n",
        "    y_vals = np.arange(1, len(sorted_ratings) + 1) / len(sorted_ratings)\n",
        "    axes[0, 1].plot(sorted_ratings, y_vals, linewidth=2, color='steelblue')\n",
        "    axes[0, 1].set_title('Cumulative Distribution of Ratings', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Rating', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Cumulative Probability', fontsize=12)\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # Density plot\n",
        "    df_sample['overall'].plot(kind='density', ax=axes[1, 0], color='steelblue', linewidth=2)\n",
        "    axes[1, 0].axvline(df_sample['overall'].mean(), color='red', linestyle='--', \n",
        "                       linewidth=2, label=f'Mean: {df_sample[\"overall\"].mean():.2f}')\n",
        "    axes[1, 0].axvline(df_sample['overall'].median(), color='green', linestyle='--', \n",
        "                       linewidth=2, label=f'Median: {df_sample[\"overall\"].median():.2f}')\n",
        "    axes[1, 0].set_title('Rating Density Plot', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Rating', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Density', fontsize=12)\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Rating by category (if verified status available)\n",
        "    if 'is_verified' in df_sample.columns:\n",
        "        verified_data = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "        non_verified_data = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "        \n",
        "        axes[1, 1].hist(verified_data, bins=20, alpha=0.6, label='Verified', color='green', density=True)\n",
        "        axes[1, 1].hist(non_verified_data, bins=20, alpha=0.6, label='Non-Verified', color='orange', density=True)\n",
        "        axes[1, 1].set_title('Rating Distribution: Verified vs Non-Verified', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xlabel('Rating', fontsize=12)\n",
        "        axes[1, 1].set_ylabel('Density', fontsize=12)\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(alpha=0.3)\n",
        "    else:\n",
        "        axes[1, 1].text(0.5, 0.5, 'Verified status not available', \n",
        "                       ha='center', va='center', transform=axes[1, 1].transAxes, fontsize=12)\n",
        "        axes[1, 1].set_title('Rating Distribution Comparison', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'advanced_statistical_plots.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.3 Comprehensive Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive distribution analysis with multiple visualizations\n",
        "if 'overall' in df_sample.columns:\n",
        "    fig = plt.figure(figsize=(20, 14))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "    \n",
        "    # 1. Rating distribution - Bar chart with percentages\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    bars = ax1.bar(rating_counts.index, rating_counts.values, \n",
        "                   color=['#ff4444', '#ff8800', '#ffbb00', '#88cc00', '#00aa00'][:len(rating_counts)],\n",
        "                   alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "    ax1.set_title('Rating Distribution', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax1.set_xlabel('Rating', fontsize=11)\n",
        "    ax1.set_ylabel('Count', fontsize=11)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    # Add percentage labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:,}\\n({height/len(df_sample)*100:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 2. Rating distribution - Pie chart\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    colors = ['#ff4444', '#ff8800', '#ffbb00', '#88cc00', '#00aa00']\n",
        "    wedges, texts, autotexts = ax2.pie(rating_counts.values, labels=rating_counts.index, \n",
        "                                        autopct='%1.1f%%', colors=colors[:len(rating_counts)],\n",
        "                                        startangle=90, textprops={'fontsize': 10})\n",
        "    ax2.set_title('Rating Distribution (Pie)', fontsize=13, fontweight='bold', pad=10)\n",
        "    \n",
        "    # 3. Rating distribution - Histogram with KDE\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    ax3.hist(df_sample['overall'], bins=20, color='steelblue', alpha=0.7, \n",
        "             edgecolor='black', density=True)\n",
        "    df_sample['overall'].plot(kind='kde', ax=ax3, color='red', linewidth=2)\n",
        "    ax3.axvline(df_sample['overall'].mean(), color='green', linestyle='--', \n",
        "                linewidth=2, label=f'Mean: {df_sample[\"overall\"].mean():.2f}')\n",
        "    ax3.set_title('Rating Distribution (Histogram + KDE)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax3.set_xlabel('Rating', fontsize=11)\n",
        "    ax3.set_ylabel('Density', fontsize=11)\n",
        "    ax3.legend(fontsize=9)\n",
        "    ax3.grid(alpha=0.3)\n",
        "    \n",
        "    # 4. Cumulative distribution\n",
        "    ax4 = fig.add_subplot(gs[1, 0])\n",
        "    sorted_ratings = np.sort(df_sample['overall'])\n",
        "    y_vals = np.arange(1, len(sorted_ratings) + 1) / len(sorted_ratings)\n",
        "    ax4.plot(sorted_ratings, y_vals, linewidth=2.5, color='steelblue')\n",
        "    ax4.fill_between(sorted_ratings, y_vals, alpha=0.3, color='steelblue')\n",
        "    ax4.axhline(0.5, color='red', linestyle='--', linewidth=1.5, label='Median')\n",
        "    ax4.set_title('Cumulative Distribution Function', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax4.set_xlabel('Rating', fontsize=11)\n",
        "    ax4.set_ylabel('Cumulative Probability', fontsize=11)\n",
        "    ax4.legend(fontsize=9)\n",
        "    ax4.grid(alpha=0.3)\n",
        "    \n",
        "    # 5. Box plot with violin plot overlay\n",
        "    ax5 = fig.add_subplot(gs[1, 1])\n",
        "    parts = ax5.violinplot([df_sample['overall']], positions=[1], showmeans=True, showmedians=True)\n",
        "    for pc in parts['bodies']:\n",
        "        pc.set_facecolor('steelblue')\n",
        "        pc.set_alpha(0.6)\n",
        "    bp = ax5.boxplot([df_sample['overall']], positions=[1], widths=0.3, patch_artist=True)\n",
        "    bp['boxes'][0].set_facecolor('coral')\n",
        "    bp['boxes'][0].set_alpha(0.7)\n",
        "    ax5.set_xticks([1])\n",
        "    ax5.set_xticklabels(['Rating'])\n",
        "    ax5.set_ylabel('Rating Value', fontsize=11)\n",
        "    ax5.set_title('Rating Distribution (Violin + Box)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax5.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 6. Rating over time (if datetime available)\n",
        "    ax6 = fig.add_subplot(gs[1, 2])\n",
        "    if 'review_datetime' in df_sample.columns:\n",
        "        df_sample['review_datetime'] = pd.to_datetime(df_sample['review_datetime'], errors='coerce')\n",
        "        df_sample['review_year'] = df_sample['review_datetime'].dt.year\n",
        "        yearly_avg = df_sample.groupby('review_year')['overall'].mean()\n",
        "        ax6.plot(yearly_avg.index, yearly_avg.values, marker='o', linewidth=2, \n",
        "                markersize=8, color='steelblue')\n",
        "        ax6.fill_between(yearly_avg.index, yearly_avg.values, alpha=0.3, color='steelblue')\n",
        "        ax6.set_title('Average Rating Over Time', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax6.set_xlabel('Year', fontsize=11)\n",
        "        ax6.set_ylabel('Average Rating', fontsize=11)\n",
        "        ax6.grid(alpha=0.3)\n",
        "    else:\n",
        "        ax6.text(0.5, 0.5, 'Temporal data not available', \n",
        "                ha='center', va='center', transform=ax6.transAxes, fontsize=12)\n",
        "        ax6.set_title('Average Rating Over Time', fontsize=13, fontweight='bold', pad=10)\n",
        "    \n",
        "    # 7. Rating by verification status\n",
        "    if 'is_verified' in df_sample.columns:\n",
        "        ax7 = fig.add_subplot(gs[2, 0])\n",
        "        verified_ratings = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "        non_verified_ratings = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "        \n",
        "        data_to_plot = [verified_ratings.values, non_verified_ratings.values]\n",
        "        bp = ax7.boxplot(data_to_plot, labels=['Verified', 'Non-Verified'], \n",
        "                        patch_artist=True, widths=0.6)\n",
        "        for patch in bp['boxes']:\n",
        "            patch.set_facecolor('steelblue')\n",
        "            patch.set_alpha(0.7)\n",
        "        ax7.set_ylabel('Rating', fontsize=11)\n",
        "        ax7.set_title('Rating by Verification Status', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax7.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 8. Rating statistics summary\n",
        "    ax8 = fig.add_subplot(gs[2, 1])\n",
        "    ax8.axis('off')\n",
        "    stats_text = f\"\"\"\n",
        "    Rating Statistics Summary\n",
        "    \n",
        "    Mean: {df_sample['overall'].mean():.3f}\n",
        "    Median: {df_sample['overall'].median():.3f}\n",
        "    Mode: {df_sample['overall'].mode()[0]}\n",
        "    Std Dev: {df_sample['overall'].std():.3f}\n",
        "    Min: {df_sample['overall'].min():.0f}\n",
        "    Max: {df_sample['overall'].max():.0f}\n",
        "    Q1: {df_sample['overall'].quantile(0.25):.2f}\n",
        "    Q3: {df_sample['overall'].quantile(0.75):.2f}\n",
        "    IQR: {df_sample['overall'].quantile(0.75) - df_sample['overall'].quantile(0.25):.2f}\n",
        "    \n",
        "    Skewness: {df_sample['overall'].skew():.3f}\n",
        "    Kurtosis: {df_sample['overall'].kurtosis():.3f}\n",
        "    \"\"\"\n",
        "    ax8.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
        "             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    # 9. Rating distribution by categories (if helpfulness available)\n",
        "    ax9 = fig.add_subplot(gs[2, 2])\n",
        "    if 'helpfulness_ratio' in df_sample.columns:\n",
        "        df_sample['helpfulness_cat'] = pd.cut(df_sample['helpfulness_ratio'], \n",
        "                                              bins=[0, 0.3, 0.6, 1.0],\n",
        "                                              labels=['Low (0-0.3)', 'Medium (0.3-0.6)', 'High (0.6-1.0)'])\n",
        "        helpful_cat_ratings = df_sample.groupby('helpfulness_cat')['overall'].mean()\n",
        "        bars = ax9.bar(range(len(helpful_cat_ratings)), helpful_cat_ratings.values,\n",
        "                      color=['#ff4444', '#ffbb00', '#00aa00'], alpha=0.7, edgecolor='black')\n",
        "        ax9.set_xticks(range(len(helpful_cat_ratings)))\n",
        "        ax9.set_xticklabels(helpful_cat_ratings.index, rotation=15, ha='right')\n",
        "        ax9.set_ylabel('Average Rating', fontsize=11)\n",
        "        ax9.set_title('Average Rating by Helpfulness Category', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax9.grid(axis='y', alpha=0.3)\n",
        "        for i, bar in enumerate(bars):\n",
        "            height = bar.get_height()\n",
        "            ax9.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "    else:\n",
        "        ax9.text(0.5, 0.5, 'Helpfulness data not available', \n",
        "                ha='center', va='center', transform=ax9.transAxes, fontsize=12)\n",
        "        ax9.set_title('Rating by Helpfulness', fontsize=13, fontweight='bold', pad=10)\n",
        "    \n",
        "    plt.suptitle('Comprehensive Rating Distribution Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.savefig(FIGURES_DIR / 'comprehensive_rating_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.4 Review Text Analysis Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive review text analysis\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    fig = plt.figure(figsize=(20, 12))\n",
        "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
        "    \n",
        "    # Clip extreme values for better visualization\n",
        "    review_lengths = df_sample['review_length_words'].clip(upper=500)\n",
        "    \n",
        "    # 1. Histogram with multiple statistics\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    n, bins, patches = ax1.hist(review_lengths, bins=50, color='steelblue', \n",
        "                                edgecolor='black', alpha=0.7)\n",
        "    # Color bars by density\n",
        "    for i, patch in enumerate(patches):\n",
        "        patch.set_facecolor(plt.cm.viridis(n[i]/max(n)))\n",
        "    ax1.axvline(review_lengths.mean(), color='red', linestyle='--', linewidth=2, \n",
        "               label=f'Mean: {review_lengths.mean():.0f}')\n",
        "    ax1.axvline(review_lengths.median(), color='green', linestyle='--', linewidth=2, \n",
        "               label=f'Median: {review_lengths.median():.0f}')\n",
        "    ax1.axvline(review_lengths.quantile(0.25), color='orange', linestyle=':', linewidth=1.5, \n",
        "               label=f'Q1: {review_lengths.quantile(0.25):.0f}')\n",
        "    ax1.axvline(review_lengths.quantile(0.75), color='orange', linestyle=':', linewidth=1.5, \n",
        "               label=f'Q3: {review_lengths.quantile(0.75):.0f}')\n",
        "    ax1.set_title('Review Length Distribution (Words)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax1.set_xlabel('Number of Words', fontsize=11)\n",
        "    ax1.set_ylabel('Frequency', fontsize=11)\n",
        "    ax1.legend(fontsize=9)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 2. Box plot with outliers\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    bp = ax2.boxplot(review_lengths, vert=True, patch_artist=True, \n",
        "                    boxprops=dict(facecolor='steelblue', alpha=0.7),\n",
        "                    showfliers=True)\n",
        "    ax2.set_title('Review Length Box Plot', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax2.set_ylabel('Number of Words', fontsize=11)\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 3. Review length by rating\n",
        "    if 'overall' in df_sample.columns:\n",
        "        ax3 = fig.add_subplot(gs[0, 2])\n",
        "        avg_length_by_rating = df_sample.groupby('overall')['review_length_words'].mean()\n",
        "        std_length_by_rating = df_sample.groupby('overall')['review_length_words'].std()\n",
        "        \n",
        "        bars = ax3.bar(avg_length_by_rating.index, avg_length_by_rating.values,\n",
        "                      yerr=std_length_by_rating.values, capsize=5,\n",
        "                      color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax3.set_title('Average Review Length by Rating', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax3.set_xlabel('Rating', fontsize=11)\n",
        "        ax3.set_ylabel('Average Words', fontsize=11)\n",
        "        ax3.grid(axis='y', alpha=0.3)\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.0f}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 4. Review length categories distribution\n",
        "    ax4 = fig.add_subplot(gs[1, 0])\n",
        "    df_sample['length_category'] = pd.cut(df_sample['review_length_words'], \n",
        "                                          bins=[0, 50, 100, 200, 500, float('inf')],\n",
        "                                          labels=['Very Short\\n(0-50)', 'Short\\n(51-100)', \n",
        "                                                 'Medium\\n(101-200)', 'Long\\n(201-500)', \n",
        "                                                 'Very Long\\n(500+)'])\n",
        "    length_cat_counts = df_sample['length_category'].value_counts().sort_index()\n",
        "    colors_cat = ['#ff4444', '#ff8800', '#ffbb00', '#88cc00', '#00aa00']\n",
        "    bars = ax4.bar(range(len(length_cat_counts)), length_cat_counts.values,\n",
        "                  color=colors_cat[:len(length_cat_counts)], alpha=0.7, edgecolor='black')\n",
        "    ax4.set_xticks(range(len(length_cat_counts)))\n",
        "    ax4.set_xticklabels(length_cat_counts.index, rotation=15, ha='right')\n",
        "    ax4.set_title('Review Length Categories', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax4.set_ylabel('Count', fontsize=11)\n",
        "    ax4.grid(axis='y', alpha=0.3)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:,}\\n({height/len(df_sample)*100:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 5. Review length percentiles\n",
        "    ax5 = fig.add_subplot(gs[1, 1])\n",
        "    percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
        "    length_percentiles = [df_sample['review_length_words'].quantile(p/100) for p in percentiles]\n",
        "    bars = ax5.bar(range(len(percentiles)), length_percentiles, \n",
        "                  color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    ax5.set_xticks(range(len(percentiles)))\n",
        "    ax5.set_xticklabels([f'{p}%' for p in percentiles])\n",
        "    ax5.set_title('Review Length Percentiles', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax5.set_xlabel('Percentile', fontsize=11)\n",
        "    ax5.set_ylabel('Words', fontsize=11)\n",
        "    ax5.grid(axis='y', alpha=0.3)\n",
        "    for i, (bar, val) in enumerate(zip(bars, length_percentiles)):\n",
        "        height = bar.get_height()\n",
        "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.0f}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 6. Review length distribution by rating (violin plot)\n",
        "    if 'overall' in df_sample.columns:\n",
        "        ax6 = fig.add_subplot(gs[1, 2])\n",
        "        rating_groups = [df_sample[df_sample['overall'] == rating]['review_length_words'].clip(upper=300).values \n",
        "                        for rating in sorted(df_sample['overall'].unique())]\n",
        "        parts = ax6.violinplot(rating_groups, positions=range(len(rating_groups)),\n",
        "                              showmeans=True, showmedians=True)\n",
        "        for pc in parts['bodies']:\n",
        "            pc.set_facecolor('steelblue')\n",
        "            pc.set_alpha(0.6)\n",
        "        ax6.set_xticks(range(len(rating_groups)))\n",
        "        ax6.set_xticklabels(sorted(df_sample['overall'].unique()))\n",
        "        ax6.set_title('Review Length Distribution by Rating', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax6.set_xlabel('Rating', fontsize=11)\n",
        "        ax6.set_ylabel('Review Length (Words)', fontsize=11)\n",
        "        ax6.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Comprehensive Review Text Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.savefig(FIGURES_DIR / 'comprehensive_review_text_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Print statistics\n",
        "    print(f\"\\nReview Length Statistics:\")\n",
        "    print(f\"  Mean: {df_sample['review_length_words'].mean():.1f} words\")\n",
        "    print(f\"  Median: {df_sample['review_length_words'].median():.1f} words\")\n",
        "    print(f\"  Std Dev: {df_sample['review_length_words'].std():.1f} words\")\n",
        "    print(f\"  Min: {df_sample['review_length_words'].min():.0f} words\")\n",
        "    print(f\"  Max: {df_sample['review_length_words'].max():.0f} words\")\n",
        "    print(f\"  Q1: {df_sample['review_length_words'].quantile(0.25):.1f} words\")\n",
        "    print(f\"  Q3: {df_sample['review_length_words'].quantile(0.75):.1f} words\")\n",
        "    print(f\"  IQR: {df_sample['review_length_words'].quantile(0.75) - df_sample['review_length_words'].quantile(0.25):.1f} words\")\n",
        "    print(f\"  Skewness: {df_sample['review_length_words'].skew():.3f}\")\n",
        "    print(f\"  Kurtosis: {df_sample['review_length_words'].kurtosis():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.5 Relationship Analysis - Multi-dimensional Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi-dimensional relationship analysis\n",
        "fig = plt.figure(figsize=(20, 14))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Rating vs Review Length - Enhanced scatter\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    plot_sample = df_sample.sample(n=min(5000, len(df_sample)), random_state=42)\n",
        "    scatter = ax1.scatter(plot_sample['review_length_words'].clip(upper=500), \n",
        "                         plot_sample['overall'],\n",
        "                         alpha=0.5, s=30, c=plot_sample['overall'], \n",
        "                         cmap='viridis', edgecolors='none')\n",
        "    ax1.set_title('Rating vs Review Length (Scatter)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax1.set_xlabel('Review Length (Words)', fontsize=11)\n",
        "    ax1.set_ylabel('Rating', fontsize=11)\n",
        "    ax1.grid(alpha=0.3)\n",
        "    plt.colorbar(scatter, ax=ax1, label='Rating')\n",
        "    \n",
        "    # Add trend line\n",
        "    z = np.polyfit(plot_sample['review_length_words'].clip(upper=500), \n",
        "                   plot_sample['overall'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax1.plot(plot_sample['review_length_words'].clip(upper=500).sort_values(),\n",
        "            p(plot_sample['review_length_words'].clip(upper=500).sort_values()),\n",
        "            \"r--\", alpha=0.8, linewidth=2, label='Trend')\n",
        "    ax1.legend(fontsize=9)\n",
        "\n",
        "# 2. Rating vs Review Length - Hexbin\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    plot_sample = df_sample.sample(n=min(10000, len(df_sample)), random_state=42)\n",
        "    hb = ax2.hexbin(plot_sample['review_length_words'].clip(upper=500), \n",
        "                   plot_sample['overall'],\n",
        "                   gridsize=30, cmap='YlOrRd', mincnt=1)\n",
        "    ax2.set_title('Rating vs Review Length (Hexbin)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax2.set_xlabel('Review Length (Words)', fontsize=11)\n",
        "    ax2.set_ylabel('Rating', fontsize=11)\n",
        "    plt.colorbar(hb, ax=ax2, label='Count')\n",
        "\n",
        "# 3. Rating vs Review Length - 2D Histogram\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    plot_sample = df_sample.sample(n=min(10000, len(df_sample)), random_state=42)\n",
        "    hist, xedges, yedges = np.histogram2d(plot_sample['review_length_words'].clip(upper=500),\n",
        "                                          plot_sample['overall'], bins=30)\n",
        "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
        "    im = ax3.imshow(hist.T, origin='lower', extent=extent, cmap='YlOrRd', aspect='auto')\n",
        "    ax3.set_title('Rating vs Review Length (2D Histogram)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax3.set_xlabel('Review Length (Words)', fontsize=11)\n",
        "    ax3.set_ylabel('Rating', fontsize=11)\n",
        "    plt.colorbar(im, ax=ax3, label='Count')\n",
        "\n",
        "# 4. Helpfulness vs Rating\n",
        "if 'helpfulness_ratio' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    ax4 = fig.add_subplot(gs[1, 0])\n",
        "    helpful_sample = df_sample[df_sample['helpfulness_ratio'].notna()].sample(\n",
        "        n=min(5000, len(df_sample[df_sample['helpfulness_ratio'].notna()])), random_state=42)\n",
        "    if len(helpful_sample) > 0:\n",
        "        scatter = ax4.scatter(helpful_sample['helpfulness_ratio'], \n",
        "                             helpful_sample['overall'],\n",
        "                             alpha=0.5, s=30, c=helpful_sample['overall'], \n",
        "                             cmap='coolwarm', edgecolors='none')\n",
        "        ax4.set_title('Helpfulness vs Rating', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax4.set_xlabel('Helpfulness Ratio', fontsize=11)\n",
        "        ax4.set_ylabel('Rating', fontsize=11)\n",
        "        ax4.grid(alpha=0.3)\n",
        "        plt.colorbar(scatter, ax=ax4, label='Rating')\n",
        "\n",
        "# 5. Average helpfulness by rating\n",
        "if 'helpfulness_ratio' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    ax5 = fig.add_subplot(gs[1, 1])\n",
        "    helpful_sample = df_sample[df_sample['helpfulness_ratio'].notna()]\n",
        "    if len(helpful_sample) > 0:\n",
        "        avg_helpful_by_rating = helpful_sample.groupby('overall')['helpfulness_ratio'].mean()\n",
        "        std_helpful_by_rating = helpful_sample.groupby('overall')['helpfulness_ratio'].std()\n",
        "        bars = ax5.bar(avg_helpful_by_rating.index, avg_helpful_by_rating.values,\n",
        "                      yerr=std_helpful_by_rating.values, capsize=5,\n",
        "                      color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax5.set_title('Average Helpfulness by Rating', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax5.set_xlabel('Rating', fontsize=11)\n",
        "        ax5.set_ylabel('Average Helpfulness Ratio', fontsize=11)\n",
        "        ax5.grid(axis='y', alpha=0.3)\n",
        "        ax5.set_xticks(avg_helpful_by_rating.index)\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# 6. Review length distribution by rating and verification\n",
        "if 'review_length_words' in df_sample.columns and 'overall' in df_sample.columns and 'is_verified' in df_sample.columns:\n",
        "    ax6 = fig.add_subplot(gs[1, 2])\n",
        "    rating_groups = []\n",
        "    labels = []\n",
        "    for rating in sorted(df_sample['overall'].unique()):\n",
        "        for verified in [True, False]:\n",
        "            data = df_sample[(df_sample['overall'] == rating) & \n",
        "                            (df_sample['is_verified'] == verified)]['review_length_words'].clip(upper=300)\n",
        "            if len(data) > 0:\n",
        "                rating_groups.append(data.values)\n",
        "                labels.append(f'{int(rating)}-{\"V\" if verified else \"NV\"}')\n",
        "    \n",
        "    if rating_groups:\n",
        "        bp = ax6.boxplot(rating_groups, labels=labels, patch_artist=True, widths=0.6)\n",
        "        for patch in bp['boxes']:\n",
        "            patch.set_facecolor('steelblue')\n",
        "            patch.set_alpha(0.7)\n",
        "        ax6.set_title('Review Length by Rating & Verification', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax6.set_xlabel('Rating-Verification', fontsize=11)\n",
        "        ax6.set_ylabel('Review Length (Words)', fontsize=11)\n",
        "        ax6.tick_params(axis='x', rotation=45)\n",
        "        ax6.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 7. Correlation heatmap (if multiple numeric columns)\n",
        "ax7 = fig.add_subplot(gs[2, 0])\n",
        "numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
        "key_cols = [col for col in numeric_cols if any(x in col.lower() for x in \n",
        "            ['overall', 'length', 'helpful', 'price', 'rating'])]\n",
        "if len(key_cols) > 1:\n",
        "    corr_matrix = df_sample[key_cols].corr()\n",
        "    im = ax7.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "    ax7.set_xticks(range(len(corr_matrix.columns)))\n",
        "    ax7.set_yticks(range(len(corr_matrix.columns)))\n",
        "    ax7.set_xticklabels(corr_matrix.columns, rotation=45, ha='right', fontsize=9)\n",
        "    ax7.set_yticklabels(corr_matrix.columns, fontsize=9)\n",
        "    ax7.set_title('Correlation Matrix', fontsize=13, fontweight='bold', pad=10)\n",
        "    # Add correlation values\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(len(corr_matrix.columns)):\n",
        "            text = ax7.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
        "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "    plt.colorbar(im, ax=ax7)\n",
        "\n",
        "# 8. Rating distribution comparison (verified vs non-verified)\n",
        "if 'is_verified' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    ax8 = fig.add_subplot(gs[2, 1])\n",
        "    verified_ratings = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "    non_verified_ratings = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "    \n",
        "    ax8.hist(verified_ratings, bins=20, alpha=0.6, label='Verified', \n",
        "            color='green', density=True, edgecolor='black')\n",
        "    ax8.hist(non_verified_ratings, bins=20, alpha=0.6, label='Non-Verified', \n",
        "            color='orange', density=True, edgecolor='black')\n",
        "    ax8.set_title('Rating Distribution: Verified vs Non-Verified', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax8.set_xlabel('Rating', fontsize=11)\n",
        "    ax8.set_ylabel('Density', fontsize=11)\n",
        "    ax8.legend(fontsize=10)\n",
        "    ax8.grid(alpha=0.3)\n",
        "\n",
        "# 9. Summary statistics table\n",
        "ax9 = fig.add_subplot(gs[2, 2])\n",
        "ax9.axis('off')\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    summary_text = f\"\"\"\n",
        "    Key Relationships Summary\n",
        "    \n",
        "    Rating ↔ Review Length:\n",
        "      Correlation: {df_sample[['overall', 'review_length_words']].corr().iloc[0,1]:.3f}\n",
        "    \n",
        "    Rating Statistics:\n",
        "      Mean: {df_sample['overall'].mean():.2f}\n",
        "      Median: {df_sample['overall'].median():.2f}\n",
        "    \n",
        "    Review Length:\n",
        "      Mean: {df_sample['review_length_words'].mean():.0f} words\n",
        "      Median: {df_sample['review_length_words'].median():.0f} words\n",
        "    \"\"\"\n",
        "    if 'helpfulness_ratio' in df_sample.columns:\n",
        "        helpful_corr = df_sample[['overall', 'helpfulness_ratio']].corr().iloc[0,1]\n",
        "        summary_text += f\"\\n    Rating ↔ Helpfulness:\\n      Correlation: {helpful_corr:.3f}\"\n",
        "    if 'is_verified' in df_sample.columns:\n",
        "        verified_mean = df_sample[df_sample['is_verified'] == True]['overall'].mean()\n",
        "        non_verified_mean = df_sample[df_sample['is_verified'] == False]['overall'].mean()\n",
        "        summary_text += f\"\\n\\n    Verified Purchase:\\n      Avg Rating: {verified_mean:.2f}\\n      Non-Verified Avg: {non_verified_mean:.2f}\"\n",
        "    \n",
        "    ax9.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
        "             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.suptitle('Multi-dimensional Relationship Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.savefig(FIGURES_DIR / 'relationship_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.6 Product and User Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Product and user-level analysis\n",
        "product_cols = [col for col in df_sample.columns if 'product' in col.lower() or 'asin' in col.lower()]\n",
        "user_cols = [col for col in df_sample.columns if 'user' in col.lower() or 'reviewer' in col.lower()]\n",
        "\n",
        "if (product_cols or user_cols) and 'overall' in df_sample.columns:\n",
        "    fig = plt.figure(figsize=(20, 12))\n",
        "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
        "    \n",
        "    product_col = product_cols[0] if product_cols else None\n",
        "    user_col = user_cols[0] if user_cols else None\n",
        "    \n",
        "    # 1. Top products by review count\n",
        "    if product_col:\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        top_products = df_sample[product_col].value_counts().head(15)\n",
        "        bars = ax1.barh(range(len(top_products)), top_products.values, \n",
        "                       color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax1.set_yticks(range(len(top_products)))\n",
        "        ax1.set_yticklabels([f\"Product {i+1}\" for i in range(len(top_products))], fontsize=9)\n",
        "        ax1.set_xlabel('Number of Reviews', fontsize=11)\n",
        "        ax1.set_title('Top 15 Products by Review Count', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax1.grid(axis='x', alpha=0.3)\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            ax1.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "                    f'{int(width):,}', ha='left', va='center', fontsize=8)\n",
        "    \n",
        "    # 2. Average rating by product (top products)\n",
        "    if product_col:\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        top_product_ids = df_sample[product_col].value_counts().head(15).index\n",
        "        avg_ratings = df_sample[df_sample[product_col].isin(top_product_ids)].groupby(product_col)['overall'].mean().sort_values(ascending=False)\n",
        "        bars = ax2.barh(range(len(avg_ratings)), avg_ratings.values, \n",
        "                      color='coral', alpha=0.7, edgecolor='black')\n",
        "        ax2.set_yticks(range(len(avg_ratings)))\n",
        "        ax2.set_yticklabels([f\"Product {i+1}\" for i in range(len(avg_ratings))], fontsize=9)\n",
        "        ax2.set_xlabel('Average Rating', fontsize=11)\n",
        "        ax2.set_title('Average Rating for Top 15 Products', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax2.set_xlim([0, 5])\n",
        "        ax2.grid(axis='x', alpha=0.3)\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            ax2.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "                    f'{width:.2f}', ha='left', va='center', fontsize=8)\n",
        "    \n",
        "    # 3. Review count distribution per product\n",
        "    if product_col:\n",
        "        ax3 = fig.add_subplot(gs[0, 2])\n",
        "        review_counts_per_product = df_sample[product_col].value_counts()\n",
        "        ax3.hist(review_counts_per_product.values, bins=50, color='steelblue', \n",
        "                edgecolor='black', alpha=0.7)\n",
        "        ax3.axvline(review_counts_per_product.mean(), color='red', linestyle='--', \n",
        "                   linewidth=2, label=f'Mean: {review_counts_per_product.mean():.1f}')\n",
        "        ax3.axvline(review_counts_per_product.median(), color='green', linestyle='--', \n",
        "                   linewidth=2, label=f'Median: {review_counts_per_product.median():.1f}')\n",
        "        ax3.set_title('Distribution of Reviews per Product', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax3.set_xlabel('Number of Reviews', fontsize=11)\n",
        "        ax3.set_ylabel('Number of Products', fontsize=11)\n",
        "        ax3.legend(fontsize=9)\n",
        "        ax3.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 4. Average rating distribution across products\n",
        "    if product_col:\n",
        "        ax4 = fig.add_subplot(gs[1, 0])\n",
        "        avg_ratings_all = df_sample.groupby(product_col)['overall'].mean()\n",
        "        ax4.hist(avg_ratings_all.values, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "        ax4.axvline(avg_ratings_all.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                   label=f'Mean: {avg_ratings_all.mean():.2f}')\n",
        "        ax4.axvline(avg_ratings_all.median(), color='green', linestyle='--', linewidth=2,\n",
        "                   label=f'Median: {avg_ratings_all.median():.2f}')\n",
        "        ax4.set_title('Distribution of Average Ratings per Product', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax4.set_xlabel('Average Rating', fontsize=11)\n",
        "        ax4.set_ylabel('Number of Products', fontsize=11)\n",
        "        ax4.legend(fontsize=9)\n",
        "        ax4.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 5. Top reviewers\n",
        "    if user_col:\n",
        "        ax5 = fig.add_subplot(gs[1, 1])\n",
        "        top_reviewers = df_sample[user_col].value_counts().head(15)\n",
        "        bars = ax5.barh(range(len(top_reviewers)), top_reviewers.values, \n",
        "                      color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax5.set_yticks(range(len(top_reviewers)))\n",
        "        ax5.set_yticklabels([f\"Reviewer {i+1}\" for i in range(len(top_reviewers))], fontsize=9)\n",
        "        ax5.set_xlabel('Number of Reviews', fontsize=11)\n",
        "        ax5.set_title('Top 15 Reviewers by Review Count', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax5.grid(axis='x', alpha=0.3)\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            ax5.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "                    f'{int(width):,}', ha='left', va='center', fontsize=8)\n",
        "    \n",
        "    # 6. Reviews per user distribution\n",
        "    if user_col:\n",
        "        ax6 = fig.add_subplot(gs[1, 2])\n",
        "        reviews_per_user = df_sample[user_col].value_counts()\n",
        "        ax6.hist(reviews_per_user.values, bins=50, color='steelblue', \n",
        "                edgecolor='black', alpha=0.7)\n",
        "        ax6.axvline(reviews_per_user.mean(), color='red', linestyle='--', \n",
        "                   linewidth=2, label=f'Mean: {reviews_per_user.mean():.1f}')\n",
        "        ax6.axvline(reviews_per_user.median(), color='green', linestyle='--', \n",
        "                   linewidth=2, label=f'Median: {reviews_per_user.median():.1f}')\n",
        "        ax6.set_title('Distribution of Reviews per User', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax6.set_xlabel('Number of Reviews', fontsize=11)\n",
        "        ax6.set_ylabel('Number of Users', fontsize=11)\n",
        "        ax6.legend(fontsize=9)\n",
        "        ax6.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Product and User Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.savefig(FIGURES_DIR / 'product_user_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Print statistics\n",
        "    if product_col:\n",
        "        print(f\"\\nProduct Statistics:\")\n",
        "        print(f\"  Total unique products: {df_sample[product_col].nunique():,}\")\n",
        "        print(f\"  Average reviews per product: {review_counts_per_product.mean():.1f}\")\n",
        "        print(f\"  Median reviews per product: {review_counts_per_product.median():.1f}\")\n",
        "        print(f\"  Average rating across all products: {avg_ratings_all.mean():.2f}\")\n",
        "        print(f\"  Products with 1 review: {(review_counts_per_product == 1).sum():,} ({(review_counts_per_product == 1).sum()/len(review_counts_per_product)*100:.1f}%)\")\n",
        "    \n",
        "    if user_col:\n",
        "        print(f\"\\nUser Statistics:\")\n",
        "        print(f\"  Total unique users: {df_sample[user_col].nunique():,}\")\n",
        "        print(f\"  Average reviews per user: {reviews_per_user.mean():.1f}\")\n",
        "        print(f\"  Median reviews per user: {reviews_per_user.median():.1f}\")\n",
        "        print(f\"  Users with 1 review: {(reviews_per_user == 1).sum():,} ({(reviews_per_user == 1).sum()/len(reviews_per_user)*100:.1f}%)\")\n",
        "else:\n",
        "    print(\"Product or User ID columns not found. Skipping product/user-level analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.7 Summary Dashboard - Key Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive summary dashboard\n",
        "fig = plt.figure(figsize=(22, 14))\n",
        "gs = fig.add_gridspec(3, 4, hspace=0.35, wspace=0.35)\n",
        "\n",
        "# 1. Key metrics summary\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.axis('off')\n",
        "metrics_text = f\"\"\"\n",
        "KEY METRICS\n",
        "\n",
        "Dataset Size:\n",
        "  Rows: {len(df_sample):,}\n",
        "  Columns: {len(df_sample.columns)}\n",
        "  Memory: {df_sample.memory_usage(deep=True).sum() / 1024**2:.1f} MB\n",
        "\n",
        "Data Quality:\n",
        "  Missing Values: {df_sample.isnull().sum().sum():,}\n",
        "  Complete Rows: {df_sample.dropna().shape[0]:,}\n",
        "  Completeness: {df_sample.dropna().shape[0]/len(df_sample)*100:.1f}%\n",
        "\"\"\"\n",
        "if 'overall' in df_sample.columns:\n",
        "    metrics_text += f\"\"\"\n",
        "Rating Stats:\n",
        "  Mean: {df_sample['overall'].mean():.2f}\n",
        "  Median: {df_sample['overall'].median():.2f}\n",
        "  Std: {df_sample['overall'].std():.2f}\n",
        "\"\"\"\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    metrics_text += f\"\"\"\n",
        "Review Length:\n",
        "  Mean: {df_sample['review_length_words'].mean():.0f} words\n",
        "  Median: {df_sample['review_length_words'].median():.0f} words\n",
        "\"\"\"\n",
        "ax1.text(0.05, 0.5, metrics_text, fontsize=10, family='monospace',\n",
        "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
        "\n",
        "# 2. Rating distribution (compact)\n",
        "if 'overall' in df_sample.columns:\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    colors = ['#ff4444', '#ff8800', '#ffbb00', '#88cc00', '#00aa00']\n",
        "    bars = ax2.bar(rating_counts.index, rating_counts.values,\n",
        "                  color=colors[:len(rating_counts)], alpha=0.8, edgecolor='black')\n",
        "    ax2.set_title('Rating Distribution', fontsize=12, fontweight='bold')\n",
        "    ax2.set_xlabel('Rating', fontsize=10)\n",
        "    ax2.set_ylabel('Count', fontsize=10)\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height/len(df_sample)*100:.1f}%', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 3. Review length distribution (compact)\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    review_lengths = df_sample['review_length_words'].clip(upper=500)\n",
        "    ax3.hist(review_lengths, bins=40, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    ax3.axvline(review_lengths.mean(), color='red', linestyle='--', linewidth=2,\n",
        "               label=f'Mean: {review_lengths.mean():.0f}')\n",
        "    ax3.set_title('Review Length Distribution', fontsize=12, fontweight='bold')\n",
        "    ax3.set_xlabel('Words', fontsize=10)\n",
        "    ax3.set_ylabel('Frequency', fontsize=10)\n",
        "    ax3.legend(fontsize=8)\n",
        "    ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Verification status\n",
        "if 'is_verified' in df_sample.columns:\n",
        "    ax4 = fig.add_subplot(gs[0, 3])\n",
        "    verified_counts = df_sample['is_verified'].value_counts()\n",
        "    colors_ver = ['#00aa00', '#ff8800']\n",
        "    bars = ax4.bar(['Verified', 'Non-Verified'], verified_counts.values,\n",
        "                  color=colors_ver, alpha=0.7, edgecolor='black')\n",
        "    ax4.set_title('Verification Status', fontsize=12, fontweight='bold')\n",
        "    ax4.set_ylabel('Count', fontsize=10)\n",
        "    ax4.grid(axis='y', alpha=0.3)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:,}\\n({height/len(df_sample)*100:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# 5. Rating vs Review Length (compact)\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    ax5 = fig.add_subplot(gs[1, 0])\n",
        "    plot_sample = df_sample.sample(n=min(3000, len(df_sample)), random_state=42)\n",
        "    scatter = ax5.scatter(plot_sample['review_length_words'].clip(upper=500),\n",
        "                         plot_sample['overall'], alpha=0.4, s=20,\n",
        "                         c=plot_sample['overall'], cmap='viridis', edgecolors='none')\n",
        "    ax5.set_title('Rating vs Review Length', fontsize=12, fontweight='bold')\n",
        "    ax5.set_xlabel('Review Length (Words)', fontsize=10)\n",
        "    ax5.set_ylabel('Rating', fontsize=10)\n",
        "    ax5.grid(alpha=0.3)\n",
        "    corr = df_sample[['overall', 'review_length_words']].corr().iloc[0,1]\n",
        "    ax5.text(0.05, 0.95, f'Corr: {corr:.3f}', transform=ax5.transAxes,\n",
        "            fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "# 6. Helpfulness analysis (if available)\n",
        "if 'helpfulness_ratio' in df_sample.columns:\n",
        "    ax6 = fig.add_subplot(gs[1, 1])\n",
        "    helpful_data = df_sample['helpfulness_ratio'].dropna()\n",
        "    if len(helpful_data) > 0:\n",
        "        ax6.hist(helpful_data, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax6.axvline(helpful_data.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                   label=f'Mean: {helpful_data.mean():.3f}')\n",
        "        ax6.set_title('Helpfulness Distribution', fontsize=12, fontweight='bold')\n",
        "        ax6.set_xlabel('Helpfulness Ratio', fontsize=10)\n",
        "        ax6.set_ylabel('Frequency', fontsize=10)\n",
        "        ax6.legend(fontsize=8)\n",
        "        ax6.grid(alpha=0.3)\n",
        "\n",
        "# 7. Verified vs Non-Verified comparison\n",
        "if 'is_verified' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    ax7 = fig.add_subplot(gs[1, 2])\n",
        "    verified_ratings = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "    non_verified_ratings = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "    \n",
        "    data_to_plot = [verified_ratings.values, non_verified_ratings.values]\n",
        "    bp = ax7.boxplot(data_to_plot, labels=['Verified', 'Non-Verified'],\n",
        "                    patch_artist=True, widths=0.6)\n",
        "    for patch in bp['boxes']:\n",
        "        patch.set_facecolor('steelblue')\n",
        "        patch.set_alpha(0.7)\n",
        "    ax7.set_title('Rating: Verified vs Non-Verified', fontsize=12, fontweight='bold')\n",
        "    ax7.set_ylabel('Rating', fontsize=10)\n",
        "    ax7.grid(axis='y', alpha=0.3)\n",
        "    diff = verified_ratings.mean() - non_verified_ratings.mean()\n",
        "    ax7.text(0.5, 0.95, f'Diff: {diff:+.2f}', transform=ax7.transAxes,\n",
        "            fontsize=9, ha='center', verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "# 8. Missing values visualization\n",
        "ax8 = fig.add_subplot(gs[1, 3])\n",
        "missing = df_sample.isnull().sum()\n",
        "missing_pct = (missing / len(df_sample)) * 100\n",
        "missing_df = pd.DataFrame({'Column': missing.index, 'Missing %': missing_pct.values})\n",
        "missing_df = missing_df[missing_df['Missing %'] > 0].sort_values('Missing %', ascending=False).head(10)\n",
        "\n",
        "if len(missing_df) > 0:\n",
        "    bars = ax8.barh(range(len(missing_df)), missing_df['Missing %'].values,\n",
        "                   color='coral', alpha=0.7, edgecolor='black')\n",
        "    ax8.set_yticks(range(len(missing_df)))\n",
        "    ax8.set_yticklabels(missing_df['Column'].values, fontsize=8)\n",
        "    ax8.set_title('Top 10 Missing Values', fontsize=12, fontweight='bold')\n",
        "    ax8.set_xlabel('Missing %', fontsize=10)\n",
        "    ax8.grid(axis='x', alpha=0.3)\n",
        "else:\n",
        "    ax8.text(0.5, 0.5, 'No missing values!', ha='center', va='center',\n",
        "            transform=ax8.transAxes, fontsize=12, fontweight='bold')\n",
        "    ax8.set_title('Missing Values', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 9. Temporal analysis (if available)\n",
        "if 'review_datetime' in df_sample.columns:\n",
        "    ax9 = fig.add_subplot(gs[2, 0])\n",
        "    df_sample['review_datetime'] = pd.to_datetime(df_sample['review_datetime'], errors='coerce')\n",
        "    df_sample['review_year'] = df_sample['review_datetime'].dt.year\n",
        "    yearly_counts = df_sample.groupby('review_year').size()\n",
        "    ax9.plot(yearly_counts.index, yearly_counts.values, marker='o', linewidth=2,\n",
        "            markersize=6, color='steelblue')\n",
        "    ax9.fill_between(yearly_counts.index, yearly_counts.values, alpha=0.3, color='steelblue')\n",
        "    ax9.set_title('Review Volume Over Time', fontsize=12, fontweight='bold')\n",
        "    ax9.set_xlabel('Year', fontsize=10)\n",
        "    ax9.set_ylabel('Count', fontsize=10)\n",
        "    ax9.grid(alpha=0.3)\n",
        "\n",
        "# 10. Correlation summary\n",
        "if 'overall' in df_sample.columns:\n",
        "    ax10 = fig.add_subplot(gs[2, 1])\n",
        "    numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    key_cols = [col for col in numeric_cols if any(x in col.lower() for x in \n",
        "                ['overall', 'length', 'helpful'])]\n",
        "    if len(key_cols) > 1:\n",
        "        corr_with_rating = df_sample[key_cols].corr()['overall'].drop('overall').sort_values(ascending=False)\n",
        "        if len(corr_with_rating) > 0:\n",
        "            bars = ax10.barh(range(len(corr_with_rating)), corr_with_rating.values,\n",
        "                           color=['red' if x < 0 else 'blue' for x in corr_with_rating.values],\n",
        "                           alpha=0.7, edgecolor='black')\n",
        "            ax10.set_yticks(range(len(corr_with_rating)))\n",
        "            ax10.set_yticklabels(corr_with_rating.index, fontsize=8)\n",
        "            ax10.set_title('Correlation with Rating', fontsize=12, fontweight='bold')\n",
        "            ax10.set_xlabel('Correlation', fontsize=10)\n",
        "            ax10.axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
        "            ax10.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 11. Distribution shape metrics\n",
        "if 'overall' in df_sample.columns:\n",
        "    ax11 = fig.add_subplot(gs[2, 2])\n",
        "    ax11.axis('off')\n",
        "    from scipy.stats import skew, kurtosis\n",
        "    skewness = skew(df_sample['overall'])\n",
        "    kurt = kurtosis(df_sample['overall'])\n",
        "    shape_text = f\"\"\"\n",
        "DISTRIBUTION SHAPE\n",
        "\n",
        "Rating:\n",
        "  Skewness: {skewness:.3f}\n",
        "    {'Right-skewed' if skewness > 0 else 'Left-skewed' if skewness < 0 else 'Symmetric'}\n",
        "  Kurtosis: {kurt:.3f}\n",
        "    {'Heavy-tailed' if kurt > 0 else 'Light-tailed' if kurt < 0 else 'Normal-tailed'}\n",
        "\"\"\"\n",
        "    if 'review_length_words' in df_sample.columns:\n",
        "        len_skew = skew(df_sample['review_length_words'])\n",
        "        len_kurt = kurtosis(df_sample['review_length_words'])\n",
        "        shape_text += f\"\"\"\n",
        "Review Length:\n",
        "  Skewness: {len_skew:.3f}\n",
        "  Kurtosis: {len_kurt:.3f}\n",
        "\"\"\"\n",
        "    ax11.text(0.05, 0.5, shape_text, fontsize=9, family='monospace',\n",
        "             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
        "\n",
        "# 12. Key insights summary\n",
        "ax12 = fig.add_subplot(gs[2, 3])\n",
        "ax12.axis('off')\n",
        "insights = []\n",
        "if 'overall' in df_sample.columns:\n",
        "    mode_rating = df_sample['overall'].mode()[0]\n",
        "    insights.append(f\"• Most common rating: {mode_rating}\")\n",
        "    if df_sample['overall'].mean() > 3.5:\n",
        "        insights.append(\"• Generally positive reviews\")\n",
        "    elif df_sample['overall'].mean() < 2.5:\n",
        "        insights.append(\"• Generally negative reviews\")\n",
        "    else:\n",
        "        insights.append(\"• Mixed review sentiment\")\n",
        "\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    avg_len = df_sample['review_length_words'].mean()\n",
        "    if avg_len > 200:\n",
        "        insights.append(\"• Reviews are generally long\")\n",
        "    elif avg_len < 100:\n",
        "        insights.append(\"• Reviews are generally short\")\n",
        "    else:\n",
        "        insights.append(\"• Moderate review length\")\n",
        "\n",
        "if 'is_verified' in df_sample.columns:\n",
        "    verified_pct = df_sample['is_verified'].sum() / len(df_sample) * 100\n",
        "    insights.append(f\"• {verified_pct:.1f}% verified purchases\")\n",
        "\n",
        "if 'helpfulness_ratio' in df_sample.columns:\n",
        "    helpful_avg = df_sample['helpfulness_ratio'].dropna().mean()\n",
        "    if helpful_avg > 0.7:\n",
        "        insights.append(\"• High helpfulness ratio\")\n",
        "    elif helpful_avg < 0.4:\n",
        "        insights.append(\"• Low helpfulness ratio\")\n",
        "\n",
        "insights_text = \"KEY INSIGHTS\\n\\n\" + \"\\n\".join(insights[:8])  # Limit to 8 insights\n",
        "ax12.text(0.05, 0.5, insights_text, fontsize=10, family='monospace',\n",
        "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "\n",
        "plt.suptitle('EDA Summary Dashboard - Key Insights', fontsize=18, fontweight='bold', y=0.995)\n",
        "plt.savefig(FIGURES_DIR / 'summary_dashboard.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== SUMMARY DASHBOARD CREATED ===\")\n",
        "print(f\"All figures saved to: {FIGURES_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review text analysis (if available)\n",
        "text_cols = [col for col in df_sample.columns if 'review' in col.lower() and 'text' in col.lower()]\n",
        "\n",
        "if text_cols and 'review_length_words' in df_sample.columns:\n",
        "    text_col = text_cols[0]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Word count distribution by rating\n",
        "    for rating in sorted(df_sample['overall'].unique()):\n",
        "        rating_data = df_sample[df_sample['overall'] == rating]['review_length_words']\n",
        "        axes[0, 0].hist(rating_data.clip(upper=300), bins=30, alpha=0.5, \n",
        "                       label=f'Rating {int(rating)}', density=True)\n",
        "    axes[0, 0].set_title('Review Length Distribution by Rating', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Review Length (Words)', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Density', fontsize=12)\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Average review length by rating\n",
        "    avg_length_by_rating = df_sample.groupby('overall')['review_length_words'].mean()\n",
        "    axes[0, 1].plot(avg_length_by_rating.index, avg_length_by_rating.values, \n",
        "                    marker='o', linewidth=2, markersize=8, color='steelblue')\n",
        "    axes[0, 1].set_title('Average Review Length by Rating', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Rating', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Average Words', fontsize=12)\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    axes[0, 1].set_xticks(avg_length_by_rating.index)\n",
        "    \n",
        "    # Review length percentiles\n",
        "    percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
        "    length_percentiles = [df_sample['review_length_words'].quantile(p/100) for p in percentiles]\n",
        "    axes[1, 0].bar(range(len(percentiles)), length_percentiles, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[1, 0].set_xticks(range(len(percentiles)))\n",
        "    axes[1, 0].set_xticklabels([f'{p}%' for p in percentiles])\n",
        "    axes[1, 0].set_title('Review Length Percentiles', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Percentile', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Words', fontsize=12)\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Review length categories\n",
        "    df_sample['length_category'] = pd.cut(df_sample['review_length_words'], \n",
        "                                          bins=[0, 50, 100, 200, 500, float('inf')],\n",
        "                                          labels=['Very Short\\n(0-50)', 'Short\\n(51-100)', \n",
        "                                                 'Medium\\n(101-200)', 'Long\\n(201-500)', \n",
        "                                                 'Very Long\\n(500+)'])\n",
        "    length_cat_counts = df_sample['length_category'].value_counts().sort_index()\n",
        "    axes[1, 1].bar(range(len(length_cat_counts)), length_cat_counts.values, \n",
        "                  color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[1, 1].set_xticks(range(len(length_cat_counts)))\n",
        "    axes[1, 1].set_xticklabels(length_cat_counts.index, rotation=45, ha='right')\n",
        "    axes[1, 1].set_title('Review Length Categories', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_ylabel('Count', fontsize=12)\n",
        "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'review_text_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nReview Length by Category:\")\n",
        "    for cat, count in length_cat_counts.items():\n",
        "        print(f\"  {cat}: {count:,} ({count/len(df_sample)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Statistical Tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Correlation analysis - Enhanced\n",
        "print(\"=== CORRELATION ANALYSIS ===\")\n",
        "numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
        "# Filter to key columns\n",
        "key_cols = [col for col in numeric_cols if any(x in col.lower() for x in \n",
        "            ['overall', 'length', 'helpful', 'price', 'rating'])]\n",
        "\n",
        "if len(key_cols) > 1:\n",
        "    corr_matrix = df_sample[key_cols].corr()\n",
        "    \n",
        "    # Enhanced correlation heatmap\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "    \n",
        "    # Standard heatmap\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=axes[0])\n",
        "    axes[0].set_title('Correlation Heatmap', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Clustered heatmap (separate figure)\n",
        "    try:\n",
        "        g = sns.clustermap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
        "                           square=True, linewidths=1, figsize=(10, 8), cbar_kws={\"shrink\": 0.8})\n",
        "        plt.savefig(FIGURES_DIR / 'correlation_heatmap_clustered.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Correlation network (simplified)\n",
        "    # Get strong correlations\n",
        "    strong_corr = []\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i+1, len(corr_matrix.columns)):\n",
        "            corr_val = corr_matrix.iloc[i, j]\n",
        "            if abs(corr_val) > 0.3:  # Threshold for strong correlation\n",
        "                strong_corr.append({\n",
        "                    'var1': corr_matrix.columns[i],\n",
        "                    'var2': corr_matrix.columns[j],\n",
        "                    'corr': corr_val\n",
        "                })\n",
        "    \n",
        "    if strong_corr:\n",
        "        corr_df = pd.DataFrame(strong_corr).sort_values('corr', key=abs, ascending=False)\n",
        "        axes[1].barh(range(len(corr_df)), corr_df['corr'].values, \n",
        "                    color=['red' if x < 0 else 'blue' for x in corr_df['corr'].values], alpha=0.7)\n",
        "        axes[1].set_yticks(range(len(corr_df)))\n",
        "        axes[1].set_yticklabels([f\"{row['var1']} vs {row['var2']}\" \n",
        "                                for _, row in corr_df.iterrows()], fontsize=9)\n",
        "        axes[1].set_xlabel('Correlation Coefficient', fontsize=12)\n",
        "        axes[1].set_title('Strong Correlations (|r| > 0.3)', fontsize=14, fontweight='bold')\n",
        "        axes[1].axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
        "        axes[1].grid(axis='x', alpha=0.3)\n",
        "    else:\n",
        "        axes[1].text(0.5, 0.5, 'No strong correlations found', \n",
        "                    ha='center', va='center', transform=axes[1].transAxes, fontsize=12)\n",
        "        axes[1].set_title('Strong Correlations', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nTop Correlations:\")\n",
        "    # Get upper triangle of correlation matrix\n",
        "    corr_pairs = corr_matrix.unstack().sort_values(ascending=False)\n",
        "    # Remove self-correlations and duplicates\n",
        "    corr_pairs = corr_pairs[corr_pairs < 1.0].drop_duplicates()\n",
        "    print(corr_pairs.head(10))\n",
        "    \n",
        "    print(\"\\nBottom Correlations (most negative):\")\n",
        "    print(corr_pairs.tail(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional statistical tests and analysis\n",
        "print(\"\\n=== ADDITIONAL STATISTICAL ANALYSIS ===\")\n",
        "\n",
        "# Normality tests for rating distribution\n",
        "if 'overall' in df_sample.columns:\n",
        "    from scipy.stats import shapiro, normaltest\n",
        "    \n",
        "    # Shapiro-Wilk test (for smaller samples)\n",
        "    if len(df_sample) <= 5000:\n",
        "        stat_sw, p_sw = shapiro(df_sample['overall'].sample(n=min(5000, len(df_sample)), random_state=42))\n",
        "        print(f\"\\nShapiro-Wilk Normality Test:\")\n",
        "        print(f\"  Statistic: {stat_sw:.4f}\")\n",
        "        print(f\"  p-value: {p_sw:.2e}\")\n",
        "        print(f\"  Normal distribution: {'Yes' if p_sw > 0.05 else 'No'}\")\n",
        "    \n",
        "    # D'Agostino's normality test\n",
        "    stat_da, p_da = normaltest(df_sample['overall'])\n",
        "    print(f\"\\nD'Agostino's Normality Test:\")\n",
        "    print(f\"  Statistic: {stat_da:.2f}\")\n",
        "    print(f\"  p-value: {p_da:.2e}\")\n",
        "    print(f\"  Normal distribution: {'Yes' if p_da > 0.05 else 'No'}\")\n",
        "\n",
        "# Skewness and Kurtosis\n",
        "if 'overall' in df_sample.columns:\n",
        "    from scipy.stats import skew, kurtosis\n",
        "    skewness = skew(df_sample['overall'])\n",
        "    kurt = kurtosis(df_sample['overall'])\n",
        "    print(f\"\\nDistribution Shape:\")\n",
        "    print(f\"  Skewness: {skewness:.3f} ({'Right-skewed' if skewness > 0 else 'Left-skewed' if skewness < 0 else 'Symmetric'})\")\n",
        "    print(f\"  Kurtosis: {kurt:.3f} ({'Heavy-tailed' if kurt > 0 else 'Light-tailed' if kurt < 0 else 'Normal-tailed'})\")\n",
        "\n",
        "# Review length statistics\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    print(f\"\\nReview Length Statistics:\")\n",
        "    print(f\"  Skewness: {skew(df_sample['review_length_words']):.3f}\")\n",
        "    print(f\"  Kurtosis: {kurtosis(df_sample['review_length_words']):.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare verified vs non-verified ratings - Enhanced statistical tests\n",
        "if 'is_verified' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    print(\"\\n=== VERIFIED VS NON-VERIFIED RATINGS ===\")\n",
        "    \n",
        "    verified_ratings = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "    non_verified_ratings = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "    \n",
        "    print(f\"Verified - Mean: {verified_ratings.mean():.2f}, Std: {verified_ratings.std():.2f}, N: {len(verified_ratings):,}\")\n",
        "    print(f\"Non-verified - Mean: {non_verified_ratings.mean():.2f}, Std: {non_verified_ratings.std():.2f}, N: {len(non_verified_ratings):,}\")\n",
        "    \n",
        "    # Multiple statistical tests\n",
        "    print(f\"\\n=== STATISTICAL TESTS ===\")\n",
        "    \n",
        "    # Mann-Whitney U Test (non-parametric)\n",
        "    statistic_mw, p_value_mw = stats.mannwhitneyu(verified_ratings, non_verified_ratings, alternative='two-sided')\n",
        "    print(f\"Mann-Whitney U Test:\")\n",
        "    print(f\"  Statistic: {statistic_mw:.2f}\")\n",
        "    print(f\"  p-value: {p_value_mw:.2e}\")\n",
        "    print(f\"  Significant difference: {'Yes' if p_value_mw < 0.05 else 'No'}\")\n",
        "    \n",
        "    # T-test (parametric)\n",
        "    statistic_t, p_value_t = stats.ttest_ind(verified_ratings, non_verified_ratings)\n",
        "    print(f\"\\nIndependent T-Test:\")\n",
        "    print(f\"  Statistic: {statistic_t:.2f}\")\n",
        "    print(f\"  p-value: {p_value_t:.2e}\")\n",
        "    print(f\"  Significant difference: {'Yes' if p_value_t < 0.05 else 'No'}\")\n",
        "    \n",
        "    # Effect size (Cohen's d)\n",
        "    pooled_std = np.sqrt(((len(verified_ratings) - 1) * verified_ratings.std()**2 + \n",
        "                         (len(non_verified_ratings) - 1) * non_verified_ratings.std()**2) / \n",
        "                        (len(verified_ratings) + len(non_verified_ratings) - 2))\n",
        "    cohens_d = (verified_ratings.mean() - non_verified_ratings.mean()) / pooled_std\n",
        "    print(f\"\\nEffect Size (Cohen's d): {cohens_d:.3f}\")\n",
        "    if abs(cohens_d) < 0.2:\n",
        "        effect_size = \"negligible\"\n",
        "    elif abs(cohens_d) < 0.5:\n",
        "        effect_size = \"small\"\n",
        "    elif abs(cohens_d) < 0.8:\n",
        "        effect_size = \"medium\"\n",
        "    else:\n",
        "        effect_size = \"large\"\n",
        "    print(f\"  Effect size interpretation: {effect_size}\")\n",
        "    \n",
        "    # Confidence intervals\n",
        "    from scipy.stats import sem, t\n",
        "    def confidence_interval(data, confidence=0.95):\n",
        "        n = len(data)\n",
        "        mean = np.mean(data)\n",
        "        std_err = sem(data)\n",
        "        h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
        "        return mean - h, mean + h\n",
        "    \n",
        "    ci_verified = confidence_interval(verified_ratings)\n",
        "    ci_non_verified = confidence_interval(non_verified_ratings)\n",
        "    print(f\"\\n95% Confidence Intervals:\")\n",
        "    print(f\"  Verified: [{ci_verified[0]:.2f}, {ci_verified[1]:.2f}]\")\n",
        "    print(f\"  Non-Verified: [{ci_non_verified[0]:.2f}, {ci_non_verified[1]:.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Temporal Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review volume over time - Enhanced temporal analysis\n",
        "if 'review_datetime' in df_sample.columns:\n",
        "    print(\"=== TEMPORAL ANALYSIS ===\")\n",
        "    \n",
        "    # Convert to datetime if not already\n",
        "    df_sample['review_datetime'] = pd.to_datetime(df_sample['review_datetime'])\n",
        "    \n",
        "    # Create time-based features\n",
        "    df_sample['review_month'] = df_sample['review_datetime'].dt.to_period('M')\n",
        "    df_sample['review_year'] = df_sample['review_datetime'].dt.year\n",
        "    df_sample['review_quarter'] = df_sample['review_datetime'].dt.quarter\n",
        "    df_sample['review_day_of_week'] = df_sample['review_datetime'].dt.day_name()\n",
        "    df_sample['review_hour'] = df_sample['review_datetime'].dt.hour\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
        "    \n",
        "    # Monthly review counts\n",
        "    monthly_counts = df_sample.groupby('review_month').size()\n",
        "    axes[0, 0].plot(range(len(monthly_counts)), monthly_counts.values, \n",
        "                   marker='o', linewidth=2, markersize=6, color='steelblue')\n",
        "    axes[0, 0].set_title('Review Volume Over Time (Monthly)', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Month Index', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Number of Reviews', fontsize=12)\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Average rating over time\n",
        "    if 'overall' in df_sample.columns:\n",
        "        monthly_avg_rating = df_sample.groupby('review_month')['overall'].mean()\n",
        "        monthly_std_rating = df_sample.groupby('review_month')['overall'].std()\n",
        "        \n",
        "        axes[0, 1].plot(range(len(monthly_avg_rating)), monthly_avg_rating.values, \n",
        "                       marker='o', linewidth=2, markersize=6, color='coral', label='Mean')\n",
        "        axes[0, 1].fill_between(range(len(monthly_avg_rating)), \n",
        "                                monthly_avg_rating.values - monthly_std_rating.values,\n",
        "                                monthly_avg_rating.values + monthly_std_rating.values,\n",
        "                                alpha=0.3, color='coral', label='±1 Std Dev')\n",
        "        axes[0, 1].set_title('Average Rating Over Time (Monthly)', fontsize=14, fontweight='bold')\n",
        "        axes[0, 1].set_xlabel('Month Index', fontsize=12)\n",
        "        axes[0, 1].set_ylabel('Average Rating', fontsize=12)\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(alpha=0.3)\n",
        "        axes[0, 1].set_ylim([0, 5])\n",
        "    \n",
        "    # Reviews by day of week\n",
        "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "    day_counts = df_sample['review_day_of_week'].value_counts().reindex(day_order, fill_value=0)\n",
        "    axes[1, 0].bar(range(len(day_counts)), day_counts.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[1, 0].set_xticks(range(len(day_counts)))\n",
        "    axes[1, 0].set_xticklabels(day_counts.index, rotation=45, ha='right')\n",
        "    axes[1, 0].set_title('Review Volume by Day of Week', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_ylabel('Number of Reviews', fontsize=12)\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Reviews by hour of day\n",
        "    hour_counts = df_sample['review_hour'].value_counts().sort_index()\n",
        "    axes[1, 1].bar(hour_counts.index, hour_counts.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    axes[1, 1].set_title('Review Volume by Hour of Day', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Hour of Day', fontsize=12)\n",
        "    axes[1, 1].set_ylabel('Number of Reviews', fontsize=12)\n",
        "    axes[1, 1].set_xticks(range(0, 24, 2))\n",
        "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(FIGURES_DIR / 'temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Yearly and quarterly analysis\n",
        "    if 'overall' in df_sample.columns:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        \n",
        "        # Yearly analysis\n",
        "        yearly_counts = df_sample.groupby('review_year').size()\n",
        "        yearly_avg_rating = df_sample.groupby('review_year')['overall'].mean()\n",
        "        \n",
        "        ax1 = axes[0]\n",
        "        ax1_twin = ax1.twinx()\n",
        "        bars = ax1.bar(yearly_counts.index, yearly_counts.values, alpha=0.6, color='steelblue', label='Count')\n",
        "        line = ax1_twin.plot(yearly_avg_rating.index, yearly_avg_rating.values, \n",
        "                            marker='o', color='coral', linewidth=2, markersize=8, label='Avg Rating')\n",
        "        ax1.set_xlabel('Year', fontsize=12)\n",
        "        ax1.set_ylabel('Number of Reviews', fontsize=12, color='steelblue')\n",
        "        ax1_twin.set_ylabel('Average Rating', fontsize=12, color='coral')\n",
        "        ax1.set_title('Review Volume and Average Rating by Year', fontsize=14, fontweight='bold')\n",
        "        ax1.tick_params(axis='y', labelcolor='steelblue')\n",
        "        ax1_twin.tick_params(axis='y', labelcolor='coral')\n",
        "        ax1.grid(alpha=0.3)\n",
        "        \n",
        "        # Quarterly analysis\n",
        "        quarterly_counts = df_sample.groupby(['review_year', 'review_quarter']).size()\n",
        "        quarterly_avg_rating = df_sample.groupby(['review_year', 'review_quarter'])['overall'].mean()\n",
        "        \n",
        "        quarters = [f\"{y}-Q{q}\" for y, q in quarterly_counts.index]\n",
        "        axes[1].bar(range(len(quarters)), quarterly_counts.values, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "        axes[1].set_xticks(range(0, len(quarters), max(1, len(quarters)//10)))\n",
        "        axes[1].set_xticklabels([quarters[i] for i in range(0, len(quarters), max(1, len(quarters)//10))], \n",
        "                               rotation=45, ha='right')\n",
        "        axes[1].set_title('Review Volume by Quarter', fontsize=14, fontweight='bold')\n",
        "        axes[1].set_ylabel('Number of Reviews', fontsize=12)\n",
        "        axes[1].grid(axis='y', alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(FIGURES_DIR / 'yearly_quarterly_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"\\nTemporal Statistics:\")\n",
        "        print(f\"  Date range: {df_sample['review_datetime'].min()} to {df_sample['review_datetime'].max()}\")\n",
        "        print(f\"  Total months: {df_sample['review_month'].nunique()}\")\n",
        "        print(f\"  Average reviews per month: {monthly_counts.mean():.0f}\")\n",
        "        print(f\"  Peak month: {monthly_counts.idxmax()} with {monthly_counts.max():,} reviews\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Advanced Visualizations - Word Cloud and Sentiment Indicators\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced visualizations: Word frequency and sentiment indicators\n",
        "try:\n",
        "    from wordcloud import WordCloud\n",
        "    wordcloud_available = True\n",
        "except ImportError:\n",
        "    wordcloud_available = False\n",
        "    print(\"WordCloud not available. Install with: pip install wordcloud\")\n",
        "\n",
        "# Create comprehensive sentiment and text analysis visualizations\n",
        "if 'review_length_words' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    fig = plt.figure(figsize=(20, 14))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "    \n",
        "    # 1. Rating sentiment distribution (positive/negative/neutral)\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    df_sample['sentiment_category'] = pd.cut(df_sample['overall'], \n",
        "                                              bins=[0, 2, 3, 5],\n",
        "                                              labels=['Negative (1-2)', 'Neutral (3)', 'Positive (4-5)'])\n",
        "    sentiment_counts = df_sample['sentiment_category'].value_counts()\n",
        "    colors_sent = ['#ff4444', '#ffbb00', '#00aa00']\n",
        "    bars = ax1.bar(range(len(sentiment_counts)), sentiment_counts.values,\n",
        "                  color=colors_sent, alpha=0.7, edgecolor='black')\n",
        "    ax1.set_xticks(range(len(sentiment_counts)))\n",
        "    ax1.set_xticklabels(sentiment_counts.index, rotation=15, ha='right')\n",
        "    ax1.set_title('Review Sentiment Distribution', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax1.set_ylabel('Count', fontsize=11)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:,}\\n({height/len(df_sample)*100:.1f}%)',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 2. Review length by sentiment category\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    sentiment_groups = [df_sample[df_sample['sentiment_category'] == cat]['review_length_words'].clip(upper=300).values \n",
        "                       for cat in sentiment_counts.index]\n",
        "    bp = ax2.boxplot(sentiment_groups, labels=sentiment_counts.index, patch_artist=True, widths=0.6)\n",
        "    for i, patch in enumerate(bp['boxes']):\n",
        "        patch.set_facecolor(colors_sent[i])\n",
        "        patch.set_alpha(0.7)\n",
        "    ax2.set_title('Review Length by Sentiment', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax2.set_ylabel('Review Length (Words)', fontsize=11)\n",
        "    ax2.tick_params(axis='x', rotation=15)\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 3. Rating distribution with normal curve overlay\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    if 'overall' in df_sample.columns:\n",
        "        rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "        ax3.bar(rating_counts.index, rating_counts.values, alpha=0.7, \n",
        "               color='steelblue', edgecolor='black', label='Actual')\n",
        "        # Overlay normal distribution\n",
        "        from scipy.stats import norm\n",
        "        mu, sigma = df_sample['overall'].mean(), df_sample['overall'].std()\n",
        "        x = np.linspace(df_sample['overall'].min(), df_sample['overall'].max(), 100)\n",
        "        y = norm.pdf(x, mu, sigma) * len(df_sample) * (df_sample['overall'].max() - df_sample['overall'].min()) / 5\n",
        "        ax3.plot(x, y, 'r--', linewidth=2, label='Normal Distribution')\n",
        "        ax3.set_title('Rating Distribution vs Normal', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax3.set_xlabel('Rating', fontsize=11)\n",
        "        ax3.set_ylabel('Count', fontsize=11)\n",
        "        ax3.legend()\n",
        "        ax3.grid(alpha=0.3)\n",
        "    \n",
        "    # 4. Cumulative rating percentage\n",
        "    ax4 = fig.add_subplot(gs[1, 0])\n",
        "    rating_sorted = np.sort(df_sample['overall'])\n",
        "    cumulative_pct = np.arange(1, len(rating_sorted) + 1) / len(rating_sorted) * 100\n",
        "    ax4.plot(rating_sorted, cumulative_pct, linewidth=2.5, color='steelblue')\n",
        "    ax4.fill_between(rating_sorted, cumulative_pct, alpha=0.3, color='steelblue')\n",
        "    ax4.axhline(50, color='red', linestyle='--', linewidth=1.5, label='50th Percentile')\n",
        "    ax4.axvline(df_sample['overall'].median(), color='green', linestyle='--', \n",
        "               linewidth=1.5, label=f'Median: {df_sample[\"overall\"].median():.1f}')\n",
        "    ax4.set_title('Cumulative Rating Distribution', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax4.set_xlabel('Rating', fontsize=11)\n",
        "    ax4.set_ylabel('Cumulative Percentage', fontsize=11)\n",
        "    ax4.legend(fontsize=9)\n",
        "    ax4.grid(alpha=0.3)\n",
        "    \n",
        "    # 5. Review length distribution with log scale\n",
        "    ax5 = fig.add_subplot(gs[1, 1])\n",
        "    review_lengths = df_sample['review_length_words'].clip(upper=1000)\n",
        "    ax5.hist(review_lengths, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    ax5.set_yscale('log')\n",
        "    ax5.axvline(review_lengths.mean(), color='red', linestyle='--', linewidth=2,\n",
        "               label=f'Mean: {review_lengths.mean():.0f}')\n",
        "    ax5.set_title('Review Length (Log Scale)', fontsize=13, fontweight='bold', pad=10)\n",
        "    ax5.set_xlabel('Review Length (Words)', fontsize=11)\n",
        "    ax5.set_ylabel('Frequency (Log Scale)', fontsize=11)\n",
        "    ax5.legend()\n",
        "    ax5.grid(alpha=0.3)\n",
        "    \n",
        "    # 6. Rating heatmap by length categories\n",
        "    ax6 = fig.add_subplot(gs[1, 2])\n",
        "    if 'review_length_words' in df_sample.columns:\n",
        "        df_sample['length_cat'] = pd.cut(df_sample['review_length_words'],\n",
        "                                         bins=[0, 50, 100, 200, 500, float('inf')],\n",
        "                                         labels=['0-50', '51-100', '101-200', '201-500', '500+'])\n",
        "        heatmap_data = pd.crosstab(df_sample['length_cat'], df_sample['overall'], normalize='index') * 100\n",
        "        im = ax6.imshow(heatmap_data.values, cmap='YlOrRd', aspect='auto')\n",
        "        ax6.set_xticks(range(len(heatmap_data.columns)))\n",
        "        ax6.set_yticks(range(len(heatmap_data.index)))\n",
        "        ax6.set_xticklabels(heatmap_data.columns)\n",
        "        ax6.set_yticklabels(heatmap_data.index)\n",
        "        ax6.set_title('Rating Distribution by Length Category', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax6.set_xlabel('Rating', fontsize=11)\n",
        "        ax6.set_ylabel('Length Category', fontsize=11)\n",
        "        plt.colorbar(im, ax=ax6, label='Percentage')\n",
        "    \n",
        "    # 7. Rating vs Review Length - Density plot\n",
        "    ax7 = fig.add_subplot(gs[2, 0])\n",
        "    if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "        plot_sample = df_sample.sample(n=min(5000, len(df_sample)), random_state=42)\n",
        "        hb = ax7.hexbin(plot_sample['review_length_words'].clip(upper=500),\n",
        "                       plot_sample['overall'], gridsize=20, cmap='YlOrRd', mincnt=1)\n",
        "        ax7.set_title('Rating vs Review Length (Density)', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax7.set_xlabel('Review Length (Words)', fontsize=11)\n",
        "        ax7.set_ylabel('Rating', fontsize=11)\n",
        "        plt.colorbar(hb, ax=ax7, label='Count')\n",
        "    \n",
        "    # 8. Rating distribution by verification - Stacked bar\n",
        "    ax8 = fig.add_subplot(gs[2, 1])\n",
        "    if 'is_verified' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "        verified_counts = df_sample[df_sample['is_verified'] == True]['overall'].value_counts().sort_index()\n",
        "        non_verified_counts = df_sample[df_sample['is_verified'] == False]['overall'].value_counts().sort_index()\n",
        "        \n",
        "        x = np.arange(len(verified_counts))\n",
        "        width = 0.6\n",
        "        ax8.bar(x, verified_counts.values, width, label='Verified', alpha=0.8, color='green')\n",
        "        ax8.bar(x, non_verified_counts.values, width, bottom=verified_counts.values,\n",
        "               label='Non-Verified', alpha=0.8, color='orange')\n",
        "        ax8.set_xlabel('Rating', fontsize=11)\n",
        "        ax8.set_ylabel('Count', fontsize=11)\n",
        "        ax8.set_title('Rating Distribution: Verified vs Non-Verified', fontsize=13, fontweight='bold', pad=10)\n",
        "        ax8.set_xticks(x)\n",
        "        ax8.set_xticklabels(verified_counts.index)\n",
        "        ax8.legend()\n",
        "        ax8.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 9. Summary statistics panel\n",
        "    ax9 = fig.add_subplot(gs[2, 2])\n",
        "    ax9.axis('off')\n",
        "    summary_text = f\"\"\"\n",
        "    ADVANCED STATISTICS\n",
        "    \n",
        "    Dataset:\n",
        "      Sample Size: {len(df_sample):,}\n",
        "      Columns: {len(df_sample.columns)}\n",
        "    \n",
        "    Rating:\n",
        "      Mean: {df_sample['overall'].mean():.3f}\n",
        "      Median: {df_sample['overall'].median():.3f}\n",
        "      Std: {df_sample['overall'].std():.3f}\n",
        "      Skew: {df_sample['overall'].skew():.3f}\n",
        "      Kurtosis: {df_sample['overall'].kurtosis():.3f}\n",
        "    \n",
        "    Review Length:\n",
        "      Mean: {df_sample['review_length_words'].mean():.0f} words\n",
        "      Median: {df_sample['review_length_words'].median():.0f} words\n",
        "      Std: {df_sample['review_length_words'].std():.0f} words\n",
        "    \"\"\"\n",
        "    if 'is_verified' in df_sample.columns:\n",
        "        verified_pct = df_sample['is_verified'].sum() / len(df_sample) * 100\n",
        "        summary_text += f\"\\n    Verification:\\n      Verified: {verified_pct:.1f}%\"\n",
        "    \n",
        "    ax9.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
        "            verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
        "    \n",
        "    plt.suptitle('Advanced Visualizations - Sentiment and Distribution Analysis', \n",
        "                fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.savefig(FIGURES_DIR / 'advanced_sentiment_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n✅ Advanced visualizations created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interactive and Comparative Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparative and interactive-style visualizations\n",
        "fig = plt.figure(figsize=(22, 16))\n",
        "gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.35)\n",
        "\n",
        "# 1. Multi-panel rating analysis\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "if 'overall' in df_sample.columns:\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(rating_counts)))\n",
        "    bars = ax1.bar(rating_counts.index, rating_counts.values, color=colors, alpha=0.8, edgecolor='black')\n",
        "    ax1.set_title('Rating Distribution (Color-coded)', fontsize=12, fontweight='bold')\n",
        "    ax1.set_xlabel('Rating', fontsize=10)\n",
        "    ax1.set_ylabel('Count', fontsize=10)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:,}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# 2. Rating distribution - Donut chart\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "if 'overall' in df_sample.columns:\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    colors = ['#ff4444', '#ff8800', '#ffbb00', '#88cc00', '#00aa00']\n",
        "    wedges, texts, autotexts = ax2.pie(rating_counts.values, labels=rating_counts.index,\n",
        "                                       autopct='%1.1f%%', colors=colors[:len(rating_counts)],\n",
        "                                       startangle=90, pctdistance=0.85)\n",
        "    # Draw circle for donut\n",
        "    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
        "    ax2.add_artist(centre_circle)\n",
        "    ax2.set_title('Rating Distribution (Donut)', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 3. Rating distribution - Waterfall style\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "if 'overall' in df_sample.columns:\n",
        "    rating_counts = df_sample['overall'].value_counts().sort_index()\n",
        "    cumulative = rating_counts.cumsum()\n",
        "    ax3.bar(rating_counts.index, rating_counts.values, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "    ax3.plot(rating_counts.index, cumulative.values, 'ro-', linewidth=2, markersize=8, label='Cumulative')\n",
        "    ax3.set_title('Rating Distribution with Cumulative', fontsize=12, fontweight='bold')\n",
        "    ax3.set_xlabel('Rating', fontsize=10)\n",
        "    ax3.set_ylabel('Count', fontsize=10)\n",
        "    ax3.legend()\n",
        "    ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Review length - Multiple distribution views\n",
        "ax4 = fig.add_subplot(gs[1, 0])\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    review_lengths = df_sample['review_length_words'].clip(upper=500)\n",
        "    ax4.hist(review_lengths, bins=40, alpha=0.6, color='steelblue', edgecolor='black', label='Histogram')\n",
        "    review_lengths.plot(kind='kde', ax=ax4, color='red', linewidth=2, label='KDE')\n",
        "    ax4.set_title('Review Length: Histogram + KDE', fontsize=12, fontweight='bold')\n",
        "    ax4.set_xlabel('Words', fontsize=10)\n",
        "    ax4.set_ylabel('Density', fontsize=10)\n",
        "    ax4.legend()\n",
        "    ax4.grid(alpha=0.3)\n",
        "\n",
        "# 5. Review length - Violin plot\n",
        "ax5 = fig.add_subplot(gs[1, 1])\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    review_lengths = df_sample['review_length_words'].clip(upper=500)\n",
        "    parts = ax5.violinplot([review_lengths], positions=[1], showmeans=True, showmedians=True)\n",
        "    for pc in parts['bodies']:\n",
        "        pc.set_facecolor('steelblue')\n",
        "        pc.set_alpha(0.7)\n",
        "    ax5.set_xticks([1])\n",
        "    ax5.set_xticklabels(['Review Length'])\n",
        "    ax5.set_ylabel('Words', fontsize=10)\n",
        "    ax5.set_title('Review Length Distribution (Violin)', fontsize=12, fontweight='bold')\n",
        "    ax5.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 6. Review length - Percentile bars\n",
        "ax6 = fig.add_subplot(gs[1, 2])\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
        "    values = [df_sample['review_length_words'].quantile(p/100) for p in percentiles]\n",
        "    colors_pct = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(percentiles)))\n",
        "    bars = ax6.barh(range(len(percentiles)), values, color=colors_pct, alpha=0.7, edgecolor='black')\n",
        "    ax6.set_yticks(range(len(percentiles)))\n",
        "    ax6.set_yticklabels([f'{p}%' for p in percentiles])\n",
        "    ax6.set_xlabel('Words', fontsize=10)\n",
        "    ax6.set_title('Review Length Percentiles', fontsize=12, fontweight='bold')\n",
        "    ax6.grid(axis='x', alpha=0.3)\n",
        "    for i, (bar, val) in enumerate(zip(bars, values)):\n",
        "        ax6.text(val, bar.get_y() + bar.get_height()/2,\n",
        "                f'{val:.0f}', ha='left', va='center', fontsize=8)\n",
        "\n",
        "# 7. Rating vs Length - Multiple views\n",
        "ax7 = fig.add_subplot(gs[2, 0])\n",
        "if 'overall' in df_sample.columns and 'review_length_words' in df_sample.columns:\n",
        "    plot_sample = df_sample.sample(n=min(3000, len(df_sample)), random_state=42)\n",
        "    scatter = ax7.scatter(plot_sample['review_length_words'].clip(upper=500),\n",
        "                         plot_sample['overall'], alpha=0.5, s=30,\n",
        "                         c=plot_sample['overall'], cmap='coolwarm', edgecolors='none')\n",
        "    # Add trend line\n",
        "    z = np.polyfit(plot_sample['review_length_words'].clip(upper=500),\n",
        "                  plot_sample['overall'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    x_trend = np.linspace(plot_sample['review_length_words'].clip(upper=500).min(),\n",
        "                         plot_sample['review_length_words'].clip(upper=500).max(), 100)\n",
        "    ax7.plot(x_trend, p(x_trend), \"r--\", alpha=0.8, linewidth=2, label='Trend')\n",
        "    ax7.set_title('Rating vs Length (with Trend)', fontsize=12, fontweight='bold')\n",
        "    ax7.set_xlabel('Review Length (Words)', fontsize=10)\n",
        "    ax7.set_ylabel('Rating', fontsize=10)\n",
        "    ax7.legend()\n",
        "    ax7.grid(alpha=0.3)\n",
        "\n",
        "# 8. Helpfulness analysis - Multiple metrics\n",
        "ax8 = fig.add_subplot(gs[2, 1])\n",
        "if 'helpfulness_ratio' in df_sample.columns:\n",
        "    helpful_data = df_sample['helpfulness_ratio'].dropna()\n",
        "    if len(helpful_data) > 0:\n",
        "        ax8.hist(helpful_data, bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "        ax8.axvline(helpful_data.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                   label=f'Mean: {helpful_data.mean():.3f}')\n",
        "        ax8.axvline(helpful_data.median(), color='green', linestyle='--', linewidth=2,\n",
        "                   label=f'Median: {helpful_data.median():.3f}')\n",
        "        ax8.set_title('Helpfulness Distribution', fontsize=12, fontweight='bold')\n",
        "        ax8.set_xlabel('Helpfulness Ratio', fontsize=10)\n",
        "        ax8.set_ylabel('Frequency', fontsize=10)\n",
        "        ax8.legend(fontsize=8)\n",
        "        ax8.grid(alpha=0.3)\n",
        "\n",
        "# 9. Verified vs Non-Verified - Multiple comparisons\n",
        "ax9 = fig.add_subplot(gs[2, 2])\n",
        "if 'is_verified' in df_sample.columns and 'overall' in df_sample.columns:\n",
        "    verified_ratings = df_sample[df_sample['is_verified'] == True]['overall']\n",
        "    non_verified_ratings = df_sample[df_sample['is_verified'] == False]['overall']\n",
        "    \n",
        "    data_to_plot = [verified_ratings.values, non_verified_ratings.values]\n",
        "    bp = ax9.boxplot(data_to_plot, labels=['Verified', 'Non-Verified'],\n",
        "                    patch_artist=True, widths=0.6, showmeans=True)\n",
        "    for i, patch in enumerate(bp['boxes']):\n",
        "        patch.set_facecolor(['green', 'orange'][i])\n",
        "        patch.set_alpha(0.7)\n",
        "    ax9.set_title('Rating: Verified vs Non-Verified', fontsize=12, fontweight='bold')\n",
        "    ax9.set_ylabel('Rating', fontsize=10)\n",
        "    ax9.grid(axis='y', alpha=0.3)\n",
        "    diff = verified_ratings.mean() - non_verified_ratings.mean()\n",
        "    ax9.text(0.5, 0.95, f'Difference: {diff:+.2f}', transform=ax9.transAxes,\n",
        "            fontsize=9, ha='center', verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "# 10. Correlation network visualization\n",
        "ax10 = fig.add_subplot(gs[3, 0])\n",
        "numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
        "key_cols = [col for col in numeric_cols if any(x in col.lower() for x in \n",
        "            ['overall', 'length', 'helpful'])]\n",
        "if len(key_cols) > 1:\n",
        "    corr_matrix = df_sample[key_cols].corr()\n",
        "    im = ax10.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "    ax10.set_xticks(range(len(corr_matrix.columns)))\n",
        "    ax10.set_yticks(range(len(corr_matrix.columns)))\n",
        "    ax10.set_xticklabels(corr_matrix.columns, rotation=45, ha='right', fontsize=9)\n",
        "    ax10.set_yticklabels(corr_matrix.columns, fontsize=9)\n",
        "    ax10.set_title('Correlation Matrix', fontsize=12, fontweight='bold')\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(len(corr_matrix.columns)):\n",
        "            text = ax10.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "    plt.colorbar(im, ax=ax10)\n",
        "\n",
        "# 11. Missing values heatmap\n",
        "ax11 = fig.add_subplot(gs[3, 1])\n",
        "missing = df_sample.isnull()\n",
        "if missing.sum().sum() > 0:\n",
        "    # Sample columns with missing values\n",
        "    cols_with_missing = missing.columns[missing.sum() > 0][:20]  # Limit to 20 columns\n",
        "    if len(cols_with_missing) > 0:\n",
        "        missing_sample = missing[cols_with_missing].sample(n=min(1000, len(df_sample)), random_state=42)\n",
        "        im = ax11.imshow(missing_sample.values.T, cmap='RdYlGn_r', aspect='auto')\n",
        "        ax11.set_yticks(range(len(cols_with_missing)))\n",
        "        ax11.set_yticklabels(cols_with_missing, fontsize=8)\n",
        "        ax11.set_title('Missing Values Pattern', fontsize=12, fontweight='bold')\n",
        "        ax11.set_xlabel('Sample Rows', fontsize=10)\n",
        "        plt.colorbar(im, ax=ax11, label='Missing (Red)')\n",
        "    else:\n",
        "        ax11.text(0.5, 0.5, 'No missing values!', ha='center', va='center',\n",
        "                 transform=ax11.transAxes, fontsize=12, fontweight='bold')\n",
        "        ax11.set_title('Missing Values Pattern', fontsize=12, fontweight='bold')\n",
        "else:\n",
        "    ax11.text(0.5, 0.5, 'No missing values!', ha='center', va='center',\n",
        "             transform=ax11.transAxes, fontsize=12, fontweight='bold')\n",
        "    ax11.set_title('Missing Values Pattern', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 12. Summary statistics panel\n",
        "ax12 = fig.add_subplot(gs[3, 2])\n",
        "ax12.axis('off')\n",
        "summary_text = f\"\"\"\n",
        "COMPARATIVE SUMMARY\n",
        "\n",
        "Key Metrics:\n",
        "  Total Reviews: {len(df_sample):,}\n",
        "  Unique Ratings: {df_sample['overall'].nunique() if 'overall' in df_sample.columns else 'N/A'}\n",
        "  Avg Rating: {df_sample['overall'].mean():.2f if 'overall' in df_sample.columns else 'N/A'}\n",
        "  Avg Length: {df_sample['review_length_words'].mean():.0f if 'review_length_words' in df_sample.columns else 'N/A'} words\n",
        "\n",
        "Data Quality:\n",
        "  Missing Values: {df_sample.isnull().sum().sum():,}\n",
        "  Complete Rows: {df_sample.dropna().shape[0]:,}\n",
        "  Completeness: {df_sample.dropna().shape[0]/len(df_sample)*100:.1f}%\n",
        "\n",
        "Distribution:\n",
        "  Rating Skew: {df_sample['overall'].skew():.3f if 'overall' in df_sample.columns else 'N/A'}\n",
        "  Length Skew: {df_sample['review_length_words'].skew():.3f if 'review_length_words' in df_sample.columns else 'N/A'}\n",
        "\"\"\"\n",
        "ax12.text(0.05, 0.5, summary_text, fontsize=9, family='monospace',\n",
        "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
        "\n",
        "plt.suptitle('Comparative and Interactive Visualizations', fontsize=18, fontweight='bold', y=0.995)\n",
        "plt.savefig(FIGURES_DIR / 'comparative_visualizations.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Comparative visualizations created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Statistical Summary and Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive statistical summary and export\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE STATISTICAL SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create summary statistics dataframe\n",
        "summary_stats = {}\n",
        "\n",
        "if 'overall' in df_sample.columns:\n",
        "    summary_stats['Rating'] = {\n",
        "        'Count': len(df_sample['overall']),\n",
        "        'Mean': df_sample['overall'].mean(),\n",
        "        'Median': df_sample['overall'].median(),\n",
        "        'Std Dev': df_sample['overall'].std(),\n",
        "        'Min': df_sample['overall'].min(),\n",
        "        'Max': df_sample['overall'].max(),\n",
        "        'Q1': df_sample['overall'].quantile(0.25),\n",
        "        'Q3': df_sample['overall'].quantile(0.75),\n",
        "        'Skewness': df_sample['overall'].skew(),\n",
        "        'Kurtosis': df_sample['overall'].kurtosis()\n",
        "    }\n",
        "\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    summary_stats['Review Length (Words)'] = {\n",
        "        'Count': len(df_sample['review_length_words']),\n",
        "        'Mean': df_sample['review_length_words'].mean(),\n",
        "        'Median': df_sample['review_length_words'].median(),\n",
        "        'Std Dev': df_sample['review_length_words'].std(),\n",
        "        'Min': df_sample['review_length_words'].min(),\n",
        "        'Max': df_sample['review_length_words'].max(),\n",
        "        'Q1': df_sample['review_length_words'].quantile(0.25),\n",
        "        'Q3': df_sample['review_length_words'].quantile(0.75),\n",
        "        'Skewness': df_sample['review_length_words'].skew(),\n",
        "        'Kurtosis': df_sample['review_length_words'].kurtosis()\n",
        "    }\n",
        "\n",
        "if 'helpfulness_ratio' in df_sample.columns:\n",
        "    helpful_data = df_sample['helpfulness_ratio'].dropna()\n",
        "    if len(helpful_data) > 0:\n",
        "        summary_stats['Helpfulness Ratio'] = {\n",
        "            'Count': len(helpful_data),\n",
        "            'Mean': helpful_data.mean(),\n",
        "            'Median': helpful_data.median(),\n",
        "            'Std Dev': helpful_data.std(),\n",
        "            'Min': helpful_data.min(),\n",
        "            'Max': helpful_data.max(),\n",
        "            'Q1': helpful_data.quantile(0.25),\n",
        "            'Q3': helpful_data.quantile(0.75),\n",
        "            'Skewness': helpful_data.skew(),\n",
        "            'Kurtosis': helpful_data.kurtosis()\n",
        "        }\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "if summary_stats:\n",
        "    summary_df = pd.DataFrame(summary_stats).T\n",
        "    print(\"\\n📊 Summary Statistics:\")\n",
        "    print(summary_df.round(3))\n",
        "    \n",
        "    # Save to CSV\n",
        "    summary_df.to_csv(REPORTS_DIR / 'summary_statistics.csv')\n",
        "    print(f\"\\n✅ Summary statistics saved to: {REPORTS_DIR / 'summary_statistics.csv'}\")\n",
        "\n",
        "# Rating distribution summary\n",
        "if 'overall' in df_sample.columns:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RATING DISTRIBUTION SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    rating_dist = df_sample['overall'].value_counts().sort_index()\n",
        "    rating_dist_pct = (rating_dist / len(df_sample) * 100).round(2)\n",
        "    \n",
        "    rating_summary = pd.DataFrame({\n",
        "        'Rating': rating_dist.index,\n",
        "        'Count': rating_dist.values,\n",
        "        'Percentage': rating_dist_pct.values\n",
        "    })\n",
        "    print(rating_summary.to_string(index=False))\n",
        "    \n",
        "    # Save rating distribution\n",
        "    rating_summary.to_csv(REPORTS_DIR / 'rating_distribution.csv', index=False)\n",
        "    print(f\"\\n✅ Rating distribution saved to: {REPORTS_DIR / 'rating_distribution.csv'}\")\n",
        "\n",
        "# Missing values summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MISSING VALUES SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "missing = df_sample.isnull().sum()\n",
        "missing_pct = (missing / len(df_sample)) * 100\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Column': missing.index,\n",
        "    'Missing Count': missing.values,\n",
        "    'Missing Percentage': missing_pct.values\n",
        "})\n",
        "missing_summary = missing_summary[missing_summary['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
        "if len(missing_summary) > 0:\n",
        "    print(missing_summary.to_string(index=False))\n",
        "    missing_summary.to_csv(REPORTS_DIR / 'missing_values_summary.csv', index=False)\n",
        "    print(f\"\\n✅ Missing values summary saved to: {REPORTS_DIR / 'missing_values_summary.csv'}\")\n",
        "else:\n",
        "    print(\"✅ No missing values found!\")\n",
        "\n",
        "# Correlation summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CORRELATION SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "numeric_cols = df_sample.select_dtypes(include=[np.number]).columns.tolist()\n",
        "key_cols = [col for col in numeric_cols if any(x in col.lower() for x in \n",
        "            ['overall', 'length', 'helpful'])]\n",
        "if len(key_cols) > 1:\n",
        "    corr_matrix = df_sample[key_cols].corr()\n",
        "    print(\"\\nCorrelation Matrix:\")\n",
        "    print(corr_matrix.round(3))\n",
        "    \n",
        "    # Save correlation matrix\n",
        "    corr_matrix.to_csv(REPORTS_DIR / 'correlation_matrix.csv')\n",
        "    print(f\"\\n✅ Correlation matrix saved to: {REPORTS_DIR / 'correlation_matrix.csv'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"✅ ALL STATISTICAL SUMMARIES EXPORTED SUCCESSFULLY!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nAll reports saved to: {REPORTS_DIR}\")\n",
        "print(f\"All figures saved to: {FIGURES_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== EDA SUMMARY ===\")\n",
        "print(f\"\\nDataset: {len(df_sample):,} rows, {len(df_sample.columns)} columns\")\n",
        "print(f\"\\nKey Findings:\")\n",
        "if 'overall' in df_sample.columns:\n",
        "    print(f\"1. Rating distribution: {dict(df_sample['overall'].value_counts().sort_index())}\")\n",
        "if 'review_length_words' in df_sample.columns:\n",
        "    print(f\"2. Average review length: {df_sample['review_length_words'].mean():.0f} words\")\n",
        "if 'is_verified' in df_sample.columns:\n",
        "    print(f\"3. Verified purchase rate: {df_sample['is_verified'].sum() / len(df_sample) * 100:.1f}%\")\n",
        "\n",
        "print(\"\\n=== NEXT STEPS ===\")\n",
        "print(\"1. Complete detailed statistical analysis\")\n",
        "print(\"2. Generate additional visualizations\")\n",
        "print(\"3. Document findings in EDA report\")\n",
        "print(\"4. Prepare for Phase 4: Sentiment Modeling\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ecom",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
